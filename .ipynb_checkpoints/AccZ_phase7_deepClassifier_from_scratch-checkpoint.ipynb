{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50001)\n",
      "[-0.02861675 -0.03248595 -0.03233876 ... -4.65763891 -4.67567335\n",
      " -4.68219963]\n",
      "(50000,)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "data = sio.loadmat('../SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "\n",
    "\n",
    "class AccZDataset(Dataset):\n",
    "    def __init__(self,start_no,range_len):\n",
    "        data = sio.loadmat('../SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "        self.start_no = start_no\n",
    "        self.range_len = range_len\n",
    "        self.data_set = data['L23MatChunk']\n",
    "        self.n_trails = len(self.data_set)\n",
    "        self.train_set = np.zeros((1,50000))\n",
    "        \n",
    "        for i in range (0,self.n_trails):\n",
    "            curr = np.asarray(self.data_set[i][0][0][self.start_no : self.start_no+self.range_len]).reshape(1,self.range_len)\n",
    "            self.train_set = np.append(self.train_set, curr, axis = 0)\n",
    "\n",
    "        self.train_set = np.delete(self.train_set, (0), axis=0) #array of 20 * 50000\n",
    "        \n",
    "        labels = []\n",
    "        for i in range(0, self.n_trails):\n",
    "            if(i < 10):\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "        \n",
    "        labels = np.asarray(labels).reshape(self.n_trails,1)\n",
    "        self.train_set = np.append(self.train_set, labels, axis = 1)\n",
    "        print(self.train_set.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.train_set[idx][:-1]\n",
    "        label = self.train_set[idx][-1]\n",
    "\n",
    "        return sample, label \n",
    "\n",
    "\n",
    "\n",
    "dataset = AccZDataset(20,50000)\n",
    "real_value, real_label = dataset[0]\n",
    "print(real_value)\n",
    "print(real_value.shape)\n",
    "print(real_label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "data = sio.loadmat('../SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "start_no = 0\n",
    "range_len = 50000\n",
    "data_set = data['L23MatChunk']\n",
    "total_set = np.zeros((1,50000))\n",
    "\n",
    "for i in range (0,n_trails):\n",
    "\n",
    "    curr = np.asarray(data_set[i][0][0][start_no : start_no+range_len]).reshape(1,range_len)\n",
    "    total_set = np.append(total_set, curr, axis = 0)\n",
    "\n",
    "total_set = np.delete(total_set, (0), axis=0) \n",
    "\n",
    "labels = []\n",
    "for i in range(0, n_trails):\n",
    "    if(i < 10):\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "\n",
    "labels = np.asarray(labels).reshape(n_trails,1)\n",
    "total_set = np.append(total_set, labels, axis = 1)\n",
    "targets_numpy = total_set[:,-1]\n",
    "features_numpy = total_set[:,:-1]\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "featuresTrain = torch.from_numpy(features_train).type(torch.FloatTensor)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.FloatTensor)\n",
    "\n",
    "featuresTest = torch.from_numpy(features_test).type(torch.FloatTensor)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.FloatTensor)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "batch_size = len(featuresTrain)\n",
    "num_epochs = 30\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "print(targets_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Designing the model\n",
    "\n",
    "filters = 1\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 1, out_channels = filters,kernel_size=25, stride=10),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = filters, out_channels = filters, kernel_size=10, stride=5),\n",
    "            nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = filters, out_channels = filters, kernel_size=10, stride=3),\n",
    "            nn.ReLU())\n",
    "        self.avgLayer = nn.AvgPool1d(10, stride = 2)\n",
    "        self.fc1 = nn.Linear(161, 1)\n",
    "#        self.fc2 = nn.Linear(64,1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "#         blah = out.detach()[0][10].view(1,1,-1)\n",
    "#         out = self.avgLayer(blah)\n",
    "#         plt.subplot(2,1,2)\n",
    "#         plt.plot(out.detach().numpy()[0][0])\n",
    "#         out = out.detach()[:][3].view(1,1,-1)\n",
    "        out = self.avgLayer(out) # batch_size * features * out of avg layer (161)\n",
    "        out = self.fc1(out)\n",
    "#         out = self.fc2(out)\n",
    "        out = self.sig(out)\n",
    "        print(out.shape) #batch_size * filters * 1 (linear layer output dimension is 1)\n",
    "        return out\n",
    "\n",
    "    \n",
    "model = ConvNet()\n",
    "learning_rate = 0.001\n",
    "# opt = optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 50000])\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]],\n",
      "\n",
      "        [[0.5083]]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# real_value, real_label = dataset[]\n",
    "\n",
    "# plt.subplot(2,1,1)\n",
    "# plt.plot()\n",
    "# real_value = torch.from_numpy(real_value)\n",
    "# real_value = real_value.view(1,1,50000)\n",
    "# real_value = real_value.float()\n",
    "\n",
    "print(featuresTrain.shape)\n",
    "output = model(featuresTrain.view(16,1,-1))\n",
    "print(output)\n",
    "\n",
    "\n",
    "\n",
    "# m = nn.Softmax(dim = 1)\n",
    "# # you softmax over the 2nd dimension\n",
    "# input = torch.randn(1,2)\n",
    "# output = m(input)\n",
    "# print(input)\n",
    "# print(output)\n",
    "\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.tensor([[1,3]], dtype = torch.float)\n",
    "# print(input.dtype)\n",
    "# print(input.shape)\n",
    "# target = torch.LongTensor([0])\n",
    "# print(target)\n",
    "# output = loss(input, target)\n",
    "# print(output)\n",
    "# # # output.backward()\n",
    "\n",
    "# torch.max(2,1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5180]],\n",
      "\n",
      "        [[0.5203]],\n",
      "\n",
      "        [[0.5204]],\n",
      "\n",
      "        [[0.5188]],\n",
      "\n",
      "        [[0.5212]],\n",
      "\n",
      "        [[0.5189]],\n",
      "\n",
      "        [[0.5185]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5182]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5185]],\n",
      "\n",
      "        [[0.5191]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5206]],\n",
      "\n",
      "        [[0.5214]],\n",
      "\n",
      "        [[0.5192]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5179]],\n",
      "\n",
      "        [[0.5202]],\n",
      "\n",
      "        [[0.5204]],\n",
      "\n",
      "        [[0.5187]],\n",
      "\n",
      "        [[0.5211]],\n",
      "\n",
      "        [[0.5188]],\n",
      "\n",
      "        [[0.5184]],\n",
      "\n",
      "        [[0.5176]],\n",
      "\n",
      "        [[0.5181]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5184]],\n",
      "\n",
      "        [[0.5190]],\n",
      "\n",
      "        [[0.5179]],\n",
      "\n",
      "        [[0.5205]],\n",
      "\n",
      "        [[0.5214]],\n",
      "\n",
      "        [[0.5192]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5178]],\n",
      "\n",
      "        [[0.5201]],\n",
      "\n",
      "        [[0.5203]],\n",
      "\n",
      "        [[0.5186]],\n",
      "\n",
      "        [[0.5210]],\n",
      "\n",
      "        [[0.5188]],\n",
      "\n",
      "        [[0.5184]],\n",
      "\n",
      "        [[0.5175]],\n",
      "\n",
      "        [[0.5181]],\n",
      "\n",
      "        [[0.5179]],\n",
      "\n",
      "        [[0.5183]],\n",
      "\n",
      "        [[0.5189]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5204]],\n",
      "\n",
      "        [[0.5213]],\n",
      "\n",
      "        [[0.5191]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5177]],\n",
      "\n",
      "        [[0.5200]],\n",
      "\n",
      "        [[0.5202]],\n",
      "\n",
      "        [[0.5186]],\n",
      "\n",
      "        [[0.5210]],\n",
      "\n",
      "        [[0.5187]],\n",
      "\n",
      "        [[0.5183]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5182]],\n",
      "\n",
      "        [[0.5189]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5203]],\n",
      "\n",
      "        [[0.5212]],\n",
      "\n",
      "        [[0.5190]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5176]],\n",
      "\n",
      "        [[0.5200]],\n",
      "\n",
      "        [[0.5201]],\n",
      "\n",
      "        [[0.5185]],\n",
      "\n",
      "        [[0.5209]],\n",
      "\n",
      "        [[0.5186]],\n",
      "\n",
      "        [[0.5182]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5179]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5182]],\n",
      "\n",
      "        [[0.5188]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5203]],\n",
      "\n",
      "        [[0.5211]],\n",
      "\n",
      "        [[0.5189]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5176]],\n",
      "\n",
      "        [[0.5199]],\n",
      "\n",
      "        [[0.5201]],\n",
      "\n",
      "        [[0.5184]],\n",
      "\n",
      "        [[0.5208]],\n",
      "\n",
      "        [[0.5185]],\n",
      "\n",
      "        [[0.5181]],\n",
      "\n",
      "        [[0.5173]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5181]],\n",
      "\n",
      "        [[0.5187]],\n",
      "\n",
      "        [[0.5176]],\n",
      "\n",
      "        [[0.5202]],\n",
      "\n",
      "        [[0.5211]],\n",
      "\n",
      "        [[0.5189]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5175]],\n",
      "\n",
      "        [[0.5198]],\n",
      "\n",
      "        [[0.5200]],\n",
      "\n",
      "        [[0.5183]],\n",
      "\n",
      "        [[0.5208]],\n",
      "\n",
      "        [[0.5185]],\n",
      "\n",
      "        [[0.5181]],\n",
      "\n",
      "        [[0.5172]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5176]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5186]],\n",
      "\n",
      "        [[0.5175]],\n",
      "\n",
      "        [[0.5201]],\n",
      "\n",
      "        [[0.5210]],\n",
      "\n",
      "        [[0.5188]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5174]],\n",
      "\n",
      "        [[0.5197]],\n",
      "\n",
      "        [[0.5199]],\n",
      "\n",
      "        [[0.5183]],\n",
      "\n",
      "        [[0.5207]],\n",
      "\n",
      "        [[0.5184]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5171]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5175]],\n",
      "\n",
      "        [[0.5179]],\n",
      "\n",
      "        [[0.5186]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5200]],\n",
      "\n",
      "        [[0.5209]],\n",
      "\n",
      "        [[0.5187]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5173]],\n",
      "\n",
      "        [[0.5197]],\n",
      "\n",
      "        [[0.5198]],\n",
      "\n",
      "        [[0.5182]],\n",
      "\n",
      "        [[0.5206]],\n",
      "\n",
      "        [[0.5183]],\n",
      "\n",
      "        [[0.5179]],\n",
      "\n",
      "        [[0.5171]],\n",
      "\n",
      "        [[0.5176]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5185]],\n",
      "\n",
      "        [[0.5173]],\n",
      "\n",
      "        [[0.5200]],\n",
      "\n",
      "        [[0.5208]],\n",
      "\n",
      "        [[0.5186]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5173]],\n",
      "\n",
      "        [[0.5196]],\n",
      "\n",
      "        [[0.5198]],\n",
      "\n",
      "        [[0.5181]],\n",
      "\n",
      "        [[0.5205]],\n",
      "\n",
      "        [[0.5182]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5170]],\n",
      "\n",
      "        [[0.5175]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5184]],\n",
      "\n",
      "        [[0.5173]],\n",
      "\n",
      "        [[0.5199]],\n",
      "\n",
      "        [[0.5208]],\n",
      "\n",
      "        [[0.5186]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5172]],\n",
      "\n",
      "        [[0.5195]],\n",
      "\n",
      "        [[0.5197]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5205]],\n",
      "\n",
      "        [[0.5182]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5169]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5173]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5183]],\n",
      "\n",
      "        [[0.5172]],\n",
      "\n",
      "        [[0.5198]],\n",
      "\n",
      "        [[0.5207]],\n",
      "\n",
      "        [[0.5185]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5171]],\n",
      "\n",
      "        [[0.5194]],\n",
      "\n",
      "        [[0.5196]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5204]],\n",
      "\n",
      "        [[0.5181]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5168]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5172]],\n",
      "\n",
      "        [[0.5176]],\n",
      "\n",
      "        [[0.5183]],\n",
      "\n",
      "        [[0.5171]],\n",
      "\n",
      "        [[0.5197]],\n",
      "\n",
      "        [[0.5206]],\n",
      "\n",
      "        [[0.5184]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5170]],\n",
      "\n",
      "        [[0.5194]],\n",
      "\n",
      "        [[0.5195]],\n",
      "\n",
      "        [[0.5179]],\n",
      "\n",
      "        [[0.5203]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5176]],\n",
      "\n",
      "        [[0.5168]],\n",
      "\n",
      "        [[0.5173]],\n",
      "\n",
      "        [[0.5171]],\n",
      "\n",
      "        [[0.5175]],\n",
      "\n",
      "        [[0.5182]],\n",
      "\n",
      "        [[0.5170]],\n",
      "\n",
      "        [[0.5197]],\n",
      "\n",
      "        [[0.5206]],\n",
      "\n",
      "        [[0.5183]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5170]],\n",
      "\n",
      "        [[0.5193]],\n",
      "\n",
      "        [[0.5195]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5202]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5175]],\n",
      "\n",
      "        [[0.5167]],\n",
      "\n",
      "        [[0.5172]],\n",
      "\n",
      "        [[0.5171]],\n",
      "\n",
      "        [[0.5175]],\n",
      "\n",
      "        [[0.5181]],\n",
      "\n",
      "        [[0.5170]],\n",
      "\n",
      "        [[0.5196]],\n",
      "\n",
      "        [[0.5205]],\n",
      "\n",
      "        [[0.5183]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5169]],\n",
      "\n",
      "        [[0.5192]],\n",
      "\n",
      "        [[0.5194]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5202]],\n",
      "\n",
      "        [[0.5179]],\n",
      "\n",
      "        [[0.5175]],\n",
      "\n",
      "        [[0.5166]],\n",
      "\n",
      "        [[0.5171]],\n",
      "\n",
      "        [[0.5170]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5181]],\n",
      "\n",
      "        [[0.5169]],\n",
      "\n",
      "        [[0.5195]],\n",
      "\n",
      "        [[0.5204]],\n",
      "\n",
      "        [[0.5182]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5168]],\n",
      "\n",
      "        [[0.5191]],\n",
      "\n",
      "        [[0.5193]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5201]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5165]],\n",
      "\n",
      "        [[0.5171]],\n",
      "\n",
      "        [[0.5169]],\n",
      "\n",
      "        [[0.5173]],\n",
      "\n",
      "        [[0.5180]],\n",
      "\n",
      "        [[0.5168]],\n",
      "\n",
      "        [[0.5195]],\n",
      "\n",
      "        [[0.5203]],\n",
      "\n",
      "        [[0.5181]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5168]],\n",
      "\n",
      "        [[0.5191]],\n",
      "\n",
      "        [[0.5193]],\n",
      "\n",
      "        [[0.5176]],\n",
      "\n",
      "        [[0.5200]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5173]],\n",
      "\n",
      "        [[0.5165]],\n",
      "\n",
      "        [[0.5170]],\n",
      "\n",
      "        [[0.5168]],\n",
      "\n",
      "        [[0.5172]],\n",
      "\n",
      "        [[0.5179]],\n",
      "\n",
      "        [[0.5167]],\n",
      "\n",
      "        [[0.5194]],\n",
      "\n",
      "        [[0.5203]],\n",
      "\n",
      "        [[0.5180]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5167]],\n",
      "\n",
      "        [[0.5190]],\n",
      "\n",
      "        [[0.5192]],\n",
      "\n",
      "        [[0.5175]],\n",
      "\n",
      "        [[0.5200]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5172]],\n",
      "\n",
      "        [[0.5164]],\n",
      "\n",
      "        [[0.5169]],\n",
      "\n",
      "        [[0.5168]],\n",
      "\n",
      "        [[0.5172]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5167]],\n",
      "\n",
      "        [[0.5193]],\n",
      "\n",
      "        [[0.5202]],\n",
      "\n",
      "        [[0.5180]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5166]],\n",
      "\n",
      "        [[0.5189]],\n",
      "\n",
      "        [[0.5191]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5199]],\n",
      "\n",
      "        [[0.5176]],\n",
      "\n",
      "        [[0.5172]],\n",
      "\n",
      "        [[0.5163]],\n",
      "\n",
      "        [[0.5168]],\n",
      "\n",
      "        [[0.5167]],\n",
      "\n",
      "        [[0.5171]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.5166]],\n",
      "\n",
      "        [[0.5192]],\n",
      "\n",
      "        [[0.5201]],\n",
      "\n",
      "        [[0.5179]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([16, 1, 1])\n",
      "tensor([[[0.5165]],\n",
      "\n",
      "        [[0.5188]],\n",
      "\n",
      "        [[0.5191]],\n",
      "\n",
      "        [[0.5174]],\n",
      "\n",
      "        [[0.5198]],\n",
      "\n",
      "        [[0.5175]],\n",
      "\n",
      "        [[0.5171]],\n",
      "\n",
      "        [[0.5162]],\n",
      "\n",
      "        [[0.5168]],\n",
      "\n",
      "        [[0.5166]],\n",
      "\n",
      "        [[0.5170]],\n",
      "\n",
      "        [[0.5177]],\n",
      "\n",
      "        [[0.5165]],\n",
      "\n",
      "        [[0.5192]],\n",
      "\n",
      "        [[0.5201]],\n",
      "\n",
      "        [[0.5178]]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "#  training model \n",
    "num_epochs = 20\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (samples, labels) in enumerate(train_loader):\n",
    "\n",
    "        train = Variable(samples.view(batch_size,1,-1))\n",
    "        labels = Variable(labels.view(batch_size,-1))\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        print(outputs)\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "#         if count % 4 == 0:\n",
    "#             # Calculate Accuracy         \n",
    "#             correct = 0\n",
    "#             total = 0\n",
    "#             # Predict test dataset\n",
    "#             for samples, labels in test_loader:\n",
    "\n",
    "#                 test = Variable(samples)\n",
    "                \n",
    "#                 # Forward propagation\n",
    "#                 outputs = model(test)\n",
    "                \n",
    "#                 # Get predictions from the maximum value\n",
    "#                 predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "#                 # Total number of labels\n",
    "#                 total += len(labels)\n",
    "\n",
    "#                 # Total correct predictions\n",
    "#                 correct += (predicted == labels).sum()\n",
    "            \n",
    "#             accuracy = 100 * correct / float(total)\n",
    "            \n",
    "        loss_list.append(loss.data)\n",
    "#         iteration_list.append(count)\n",
    "#         accuracy_list.append(accuracy)\n",
    "\n",
    "#         print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))\n",
    "# plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-37033c220095>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Trail number is generated here using random function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mreal_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mreal_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainSet' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training the model\n",
    "\n",
    "#the model is currently trained with all trails (20 in total) in order to improve accuracy\n",
    "\n",
    "num_epochs = 20 #number of sets of 50000 values required to train the model\n",
    "losses = []\n",
    "for x in range(num_epochs):\n",
    "    if x % 2 == 0:\n",
    "        value = np.random.randint(0,8)\n",
    "    else:\n",
    "        value = np.random.randint(11,18) #Trail number is generated here using random function\n",
    "    print(value)\n",
    "    real_value, real_label = trainSet(value)\n",
    "\n",
    "    real_value = torch.from_numpy(real_value)\n",
    "    real_value = real_value.view(1,1,50000)\n",
    "    real_value = Variable(real_value.float())\n",
    "    if value < 10:\n",
    "        real_label1 = Variable(torch.LongTensor([1])) #target label is decided based on the trail number chosen by random function\n",
    "    else:\n",
    "        real_label1 = Variable(torch.LongTensor([0]))\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    \n",
    "    output = model(real_value)\n",
    "    \n",
    "    loss = criterion(output, real_label1)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    opt.step()\n",
    "    if(loss < 1.0 and x % 20 == 0):\n",
    "        losses.append(loss.data.numpy()) \n",
    "    \n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000\n",
      "(50000,)\n",
      "torch.Size([1, 2])\n",
      "torch.float32\n",
      "tensor([[0.1393, 0.0007]])\n",
      "tensor([0])\n",
      "tensor(0.6263)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testing the model\n",
    "model.eval()\n",
    "real_value, real_label = trainSet(1)\n",
    "real_value = torch.from_numpy(real_value)\n",
    "real_value = real_value.view(1,1,50000)\n",
    "real_value = Variable(real_value.float())\n",
    "real_label = Variable(torch.LongTensor([0]))\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(real_value)\n",
    "print(output)\n",
    "print(real_label)\n",
    "loss = criterion(output, real_label)\n",
    "\n",
    "# trial_no_2_test = np.random.randint(18,20)\n",
    "# trial_no_1_test = np.random.randint(8,10)\n",
    "\n",
    "\n",
    "# trial_no_test = np.random.randint(trial_no_1_test, trial_no_2_test)\n",
    "# print(trial_no_test)\n",
    "\n",
    "# real_value, real_label = trainSet(trial_no_test)\n",
    "\n",
    "# real_value = torch.from_numpy(real_value)\n",
    "# real_value = real_value.view(1,1,50000)\n",
    "# real_value = real_value.float()\n",
    "\n",
    "# output = model(real_value)\n",
    "# nn.softmax(output)\n",
    "\n",
    "# print(output)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "14\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trial_no_2 = random.randrange(11,18,1)\n",
    "trial_no_1 = random.randrange(0,8,1)\n",
    "print(trial_no_1)\n",
    "print(trial_no_2)\n",
    "\n",
    "trial_no_train = random.randint(trial_no_1, trial_no_2)\n",
    "print(trial_no_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
