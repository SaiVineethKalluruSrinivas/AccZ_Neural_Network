{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50001)\n",
      "[0.04913539 0.0478669  0.05771144 ... 0.16863332 0.05331072 0.04423187]\n",
      "(50000,)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import CubicSpline      \n",
    "from transforms3d.axangles import axangle2mat  \n",
    "\n",
    "\n",
    "\n",
    "data = sio.loadmat('./SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "\n",
    "\n",
    "class AccZDataset(Dataset):\n",
    "    def __init__(self,start_no,range_len):\n",
    "        data = sio.loadmat('./SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "        self.start_no = start_no\n",
    "        self.range_len = range_len\n",
    "        self.data_set = data['L23MatChunk']\n",
    "        self.n_trails = len(self.data_set)\n",
    "        self.train_set = np.zeros((1,50000))\n",
    "        \n",
    "        for i in range (0,self.n_trails):\n",
    "            curr = np.asarray(self.data_set[i][0][0][self.start_no : self.start_no+self.range_len]).reshape(1,self.range_len)\n",
    "            self.train_set = np.append(self.train_set, curr, axis = 0)\n",
    "\n",
    "        self.train_set = np.delete(self.train_set, (0), axis=0) #array of 20 * 50000\n",
    "        \n",
    "        labels = []\n",
    "        for i in range(0, self.n_trails):\n",
    "            if(i < 10):\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "        \n",
    "        labels = np.asarray(labels).reshape(self.n_trails,1)\n",
    "        self.train_set = np.append(self.train_set, labels, axis = 1)\n",
    "        print(self.train_set.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.train_set[idx][:-1]\n",
    "        label = self.train_set[idx][-1]\n",
    "\n",
    "        return sample, label \n",
    "\n",
    "\n",
    "\n",
    "dataset = AccZDataset(20,50000)\n",
    "real_value, real_label = dataset[13]\n",
    "print(real_value)\n",
    "print(real_value.shape)\n",
    "print(real_label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET PREPARATION FOR TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subaru Features numpy (21, 50000)\n",
      "Subaru Targets numpy (21,)\n"
     ]
    }
   ],
   "source": [
    "#DATASET PREPERATION\n",
    "\n",
    "\n",
    "data = sio.loadmat('./SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "start_no = 0\n",
    "range_len = 50000\n",
    "data_set = data['L23MatChunk']\n",
    "n_trials = len(data_set)\n",
    "total_set = np.zeros((1,50000))\n",
    "\n",
    "for i in range (20):\n",
    "\n",
    "    curr = np.asarray(data_set[i][0][0][start_no : start_no+range_len]).reshape(1,range_len)\n",
    "    total_set = np.append(total_set, curr, axis = 0)\n",
    "\n",
    "total_set = np.delete(total_set, (0), axis=0) \n",
    "\n",
    "labels = []\n",
    "for i in range(0, n_trials):\n",
    "    if(i < 10):\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "\n",
    "labels = np.asarray(labels).reshape(n_trials,1)\n",
    "total_set = np.append(total_set, labels, axis = 1)\n",
    "\n",
    "total_set = np.append(total_set, total_set[0,:].reshape(1,-1), axis = 0)\n",
    "su_targets_numpy = total_set[:,-1]\n",
    "su_features_numpy = total_set[:,:-1]\n",
    "print(\"Subaru Features numpy {}\".format(su_features_numpy.shape))\n",
    "print(\"Subaru Targets numpy {}\".format(su_targets_numpy.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET PREPARATION FOR TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volkswagen Features numpy (21, 50000)\n",
      "Volkswagen Targets numpy (21,)\n"
     ]
    }
   ],
   "source": [
    "vw_data = sio.loadmat('./VWVW_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "vw_start_no = 0\n",
    "vw_range_len = 50000\n",
    "vw_data_set = data['L23MatChunk']\n",
    "vw_n_trials = len(data_set)\n",
    "vw_total_set = np.zeros((1,50000))\n",
    "\n",
    "for i in range (20):\n",
    "\n",
    "    vw_curr = np.asarray(vw_data_set[i][0][0][vw_start_no : vw_start_no + vw_range_len]).reshape(1,vw_range_len)\n",
    "    vw_total_set = np.append(vw_total_set, vw_curr, axis = 0)\n",
    "\n",
    "vw_total_set = np.delete(vw_total_set, (0), axis=0) \n",
    "\n",
    "vw_labels = []\n",
    "for i in range(0, vw_n_trials):\n",
    "    if(i < 10):\n",
    "        vw_labels.append(0)\n",
    "    else:\n",
    "        vw_labels.append(1)\n",
    "\n",
    "vw_labels = np.asarray(vw_labels).reshape(vw_n_trials,1)\n",
    "vw_total_set = np.append(vw_total_set, vw_labels, axis = 1)\n",
    "\n",
    "vw_total_set = np.append(vw_total_set, vw_total_set[0,:].reshape(1,-1), axis = 0)\n",
    "vw_targets_numpy = vw_total_set[:,-1]\n",
    "vw_features_numpy = vw_total_set[:,:-1]\n",
    "print(\"Volkswagen Features numpy {}\".format(vw_features_numpy.shape))\n",
    "print(\"Volkswagen Targets numpy {}\".format(vw_targets_numpy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numpy = np.append(su_features_numpy,vw_features_numpy,axis=0)\n",
    "targets_numpy = np.append(su_targets_numpy,vw_targets_numpy,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_targets_numpy = targets_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FeaturesNumpy Database\n",
      "(42, 50000)\n",
      "Original TargetsNumpy Database\n",
      "(42,)\n",
      "FeaturesNumpy Output shape after jittering\n",
      "(630, 50000)\n",
      "TargetsNumpy Output shape after jittering\n",
      "(630,)\n",
      "FeaturesNumpy Output shape after magwarping\n",
      "(1218, 50000)\n",
      "TargetsNumpy Output shape after magwarping\n",
      "(1218,)\n"
     ]
    }
   ],
   "source": [
    "#DATA AUGMENTATION\n",
    "#SINGLE KERNEL \n",
    "\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "features_numpy_new = features_numpy.T\n",
    "\n",
    "print('Original FeaturesNumpy Database')\n",
    "print(features_numpy.shape)\n",
    "print('Original TargetsNumpy Database')\n",
    "print(targets_numpy.shape)\n",
    "\n",
    "\n",
    "#perform jittering\n",
    "def DA_Jitter(X, sigma= 0.05):\n",
    "    myNoise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n",
    "    return X+myNoise\n",
    "\n",
    "#perform scaling\n",
    "def DA_Scaling(X, sigma=0.1):\n",
    "    scalingFactor = np.random.normal(loc=1.0, scale=sigma, size=(1,X.shape[1])) # shape=(1,3)\n",
    "    myNoise = np.matmul(np.ones((X.shape[0],1)), scalingFactor)\n",
    "    return X*myNoise\n",
    "\n",
    "#perform magnitude warping \n",
    "def GenerateRandomCurves(X, sigma=0.2, knot=4):\n",
    "    xx = (np.ones((X.shape[1],1))*(np.arange(0,X.shape[0], (X.shape[0]-1)/(knot+1)))).transpose()\n",
    "    yy = np.random.normal(loc=1.0, scale=sigma, size=(knot+2, X.shape[1]))\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    cs_x = CubicSpline(xx[:,0], yy[:,0])\n",
    "    return np.array([cs_x(x_range)]).transpose()\n",
    "\n",
    "def DA_MagWarp(X, sigma):\n",
    "    return X * GenerateRandomCurves(X, sigma)\n",
    "\n",
    "#performing Rotation\n",
    "percent_value = 1\n",
    "percent_shift = (range_len / 100) * percent_value\n",
    "def DA_Rotation(X):\n",
    "    shift = np.random.randint(low=0 , high = percent_shift) #giving percent_value shift (if percent_value is 1, then 1% shift)\n",
    "    return np.roll(X, shift)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#implement jittering\n",
    "n_sets_jitter = 14\n",
    "sigma = [0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.3,0.7,0.9,0.1]\n",
    "#number of values in sigma list should match the n_sets_jitter value\n",
    "for j in range (n_sets_jitter):\n",
    "    for i in range(42):\n",
    "        features_numpy = np.append(features_numpy, DA_Jitter(features_numpy_new[:,i], sigma[j]).reshape(1,-1), axis = 0)\n",
    "    targets_numpy = np.append(targets_numpy, initial_targets_numpy, axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "print('FeaturesNumpy Output shape after jittering')\n",
    "print(features_numpy.shape)\n",
    "print('TargetsNumpy Output shape after jittering')\n",
    "print(targets_numpy.shape)\n",
    "\n",
    "# #implement scaling\n",
    "# features_numpy_new = features_numpy.T\n",
    "# n_sets_scaling = 22\n",
    "# sigma = [0.2,0.5,0.3,0.4,0.2,0.6,0.8,0.9,0.1,0.7,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.31,0.57,0.73]\n",
    "\n",
    "\n",
    "# for j in range (n_sets_scaling):\n",
    "#     for i in range(20):\n",
    "#         features_numpy = np.append(features_numpy, DA_Scaling(features_numpy_new[:,0].reshape(-1,1), sigma[j]).reshape(1,-1), axis = 0)\n",
    "#     targets_numpy = np.append(targets_numpy, targets_numpy[0:20], axis = 0)\n",
    "    \n",
    "\n",
    "# print('FeaturesNumpy Output shape after scaling')\n",
    "# print(features_numpy.shape)\n",
    "# print('TargetsNumpy Output shape after scaling')\n",
    "# print(targets_numpy.shape)\n",
    "\n",
    "\n",
    "#implement magnitude warping\n",
    "features_numpy_new = features_numpy.T\n",
    "n_sets_magwarp = 14\n",
    "sigma = [0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.3,0.7,0.9,0.1]\n",
    "#number of values in sigma list should match the n_sets_jitter value\n",
    "for j in range (n_sets_magwarp):\n",
    "    for i in range(42):\n",
    "        features_numpy = np.append(features_numpy, DA_MagWarp(features_numpy_new[:,i].reshape(-1,1), sigma[j]).reshape(1,-1), axis = 0)\n",
    "    targets_numpy = np.append(targets_numpy, initial_targets_numpy, axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "print('FeaturesNumpy Output shape after magwarping')\n",
    "print(features_numpy.shape)\n",
    "print('TargetsNumpy Output shape after magwarping')\n",
    "print(targets_numpy.shape)\n",
    "\n",
    "# #implement Rotation\n",
    "# features_numpy_new = features_numpy.T\n",
    "# n_sets_rotation = 14\n",
    "\n",
    "# for j in range (n_sets_rotation):\n",
    "#     for i in range(20):\n",
    "#         features_numpy = np.append(features_numpy, DA_Rotation(features_numpy_new[:,i].reshape(-1,1)).reshape(1,-1), axis = 0)\n",
    "#     targets_numpy = np.append(targets_numpy, initial_targets_numpy, axis = 0)\n",
    "\n",
    "\n",
    "# print('FeaturesNumpy Output shape after rotation')\n",
    "# print(features_numpy.shape)\n",
    "# print('TargetsNumpy Output shape after rotation')\n",
    "# print(targets_numpy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vw FeaturesNumpy Output shape after time warping\n",
      "(1638, 50000)\n",
      "vw TargetsNumpy Output shape after time warping\n",
      "(1638,)\n"
     ]
    }
   ],
   "source": [
    "#implementation of time warping\n",
    "def GenerateRandomCurves(X, sigma=0.2, knot=4):\n",
    "    xx = (np.ones((X.shape[1],1))*(np.arange(0,X.shape[0], (X.shape[0]-1)/(knot+1)))).transpose()\n",
    "    yy = np.random.normal(loc=1.0, scale=sigma, size=(knot+2, X.shape[1]))\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    cs_x = CubicSpline(xx[:,0], yy[:,0])\n",
    "    cs_y = CubicSpline(xx[:,1], yy[:,1])\n",
    "    cs_z = CubicSpline(xx[:,2], yy[:,2])\n",
    "    return np.array([cs_x(x_range),cs_y(x_range),cs_z(x_range)]).transpose()\n",
    "\n",
    "def DistortTimesteps(X, sigma=0.2):\n",
    "    tt = GenerateRandomCurves(X, sigma) # Regard these samples aroun 1 as time intervals\n",
    "    tt_cum = np.cumsum(tt, axis=0)        # Add intervals to make a cumulative graph\n",
    "    # Make the last value to have X.shape[0]\n",
    "    t_scale = [(X.shape[0]-1)/tt_cum[-1,0],(X.shape[0]-1)/tt_cum[-1,1],(X.shape[0]-1)/tt_cum[-1,2]]\n",
    "    tt_cum[:,0] = tt_cum[:,0]*t_scale[0]\n",
    "    tt_cum[:,1] = tt_cum[:,1]*t_scale[1]\n",
    "    tt_cum[:,2] = tt_cum[:,2]*t_scale[2]\n",
    "    return tt_cum\n",
    "\n",
    "def DA_TimeWarp(X, sigma=0.2):\n",
    "    tt_new = DistortTimesteps(X, sigma)\n",
    "    X_new = np.zeros(X.shape)\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    X_new[:,0] = np.interp(x_range, tt_new[:,0], X[:,0])\n",
    "    X_new[:,1] = np.interp(x_range, tt_new[:,1], X[:,1])\n",
    "    X_new[:,2] = np.interp(x_range, tt_new[:,2], X[:,2])\n",
    "    return X_new\n",
    "\n",
    "\n",
    "features_numpy_new = features_numpy.T\n",
    "\n",
    "n_sets_time_warping = 10\n",
    "sigmas = [0.3,0.15,0.1,0.25,0.2,0.05,0.27,0.37,0.43,0.13]\n",
    "\n",
    "for j in range (n_sets_time_warping):\n",
    "    for i in range(0,42,3):\n",
    "        ip = features_numpy_new[:,i:i+3]\n",
    "        features_numpy = np.append(features_numpy, DA_TimeWarp(ip, sigmas[j]).T , axis = 0)\n",
    "    targets_numpy = np.append(targets_numpy,initial_targets_numpy,axis = 0)\n",
    "# targets_numpy = np.repeat(targets_numpy, n_sets_time_warping+1)\n",
    "\n",
    "print('vw FeaturesNumpy Output shape after time warping')\n",
    "print(features_numpy.shape)\n",
    "print('vw TargetsNumpy Output shape after time warping')\n",
    "print(targets_numpy.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tmp_features', features_numpy)\n",
    "np.save('tmp_targets', targets_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset with subaru and volkswagen data with time warping- Features shape: (1638, 50000)\n",
      "Total dataset with subaru and volkswagen data with time warping- Targets shape: (1638,)\n"
     ]
    }
   ],
   "source": [
    "print('Total dataset with subaru and volkswagen data with time warping- Features shape:', features_numpy.shape)\n",
    "print('Total dataset with subaru and volkswagen data with time warping- Targets shape:', targets_numpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET PREPARATION FOR TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset dimensions\n",
      "Shape of Features Train Dataset\n",
      "torch.Size([1310, 50000])\n",
      "Shape of Targets Train Dataset\n",
      "torch.Size([1310])\n",
      "Shape of Features Validation Dataset\n",
      "torch.Size([328, 50000])\n",
      "Shape of Targets Validation Dataset\n",
      "torch.Size([328])\n"
     ]
    }
   ],
   "source": [
    "#TRAIN AND TEST SPLIT\n",
    "\n",
    "\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42)\n",
    "\n",
    "\n",
    "featuresTrain = torch.from_numpy(features_train).type(torch.FloatTensor)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.FloatTensor)\n",
    "\n",
    "featuresTest = torch.from_numpy(features_test).type(torch.FloatTensor)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "batch_size_val = 8\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "val_loader = torch.utils.data.DataLoader(test, batch_size = batch_size_val, shuffle = False)\n",
    "\n",
    "\n",
    "print(\"Training dataset dimensions\")\n",
    "print('Shape of Features Train Dataset')\n",
    "print(featuresTrain.size())\n",
    "print('Shape of Targets Train Dataset')\n",
    "print(targetsTrain.size())\n",
    "print('Shape of Features Validation Dataset')\n",
    "print(featuresTest.size())\n",
    "print('Shape of Targets Validation Dataset')\n",
    "print(targetsTest.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv1d(1, 1, kernel_size=(25,), stride=(10,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1d(1, 1, kernel_size=(10,), stride=(5,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1d(1, 1, kernel_size=(10,), stride=(3,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (avgLayer): AvgPool1d(kernel_size=(10,), stride=(2,), padding=(0,))\n",
       "  (fc1): Linear(in_features=161, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Designing the model\n",
    "\n",
    "filters = 1\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 1, out_channels = filters,kernel_size=25, stride=10),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(filters))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = filters, out_channels = filters, kernel_size=10, stride=5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(filters))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = filters, out_channels = filters, kernel_size=10, stride=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(filters)) # 250\n",
    "        self.avgLayer = nn.AvgPool1d(10, stride = 2)\n",
    "        self.fc1 = nn.Linear(161,2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out) \n",
    "        out = self.avgLayer(out)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        return Variable(hidden)\n",
    "    \n",
    "    \n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        torch.nn.init.xavier_uniform(m.weight.data, nn.init.calculate_gain('relu'))\n",
    "        m.bias.data.zero_()\n",
    "    \n",
    "\n",
    "model = ConvNet()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saivineethks/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saivineethks/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1  Loss: 0.4216979146003723  Accuracy: 88 %\n",
      "Current Epoch: 1\n",
      "Iteration: 2  Loss: 0.2907894253730774  Accuracy: 91 %\n",
      "Current Epoch: 2\n",
      "Iteration: 3  Loss: 0.23513217270374298  Accuracy: 93 %\n",
      "Current Epoch: 3\n",
      "Iteration: 4  Loss: 0.20523639023303986  Accuracy: 95 %\n",
      "Current Epoch: 4\n",
      "Iteration: 5  Loss: 0.18150924146175385  Accuracy: 95 %\n",
      "Current Epoch: 5\n",
      "Iteration: 6  Loss: 0.17000789940357208  Accuracy: 94 %\n",
      "Current Epoch: 6\n",
      "Iteration: 7  Loss: 0.15954557061195374  Accuracy: 95 %\n",
      "Current Epoch: 7\n",
      "Iteration: 8  Loss: 0.15341107547283173  Accuracy: 94 %\n",
      "Current Epoch: 8\n",
      "Iteration: 9  Loss: 0.14027626812458038  Accuracy: 95 %\n",
      "Current Epoch: 9\n",
      "Iteration: 10  Loss: 0.13856840133666992  Accuracy: 95 %\n",
      "Current Epoch: 10\n",
      "Iteration: 11  Loss: 0.13191893696784973  Accuracy: 95 %\n",
      "Current Epoch: 11\n",
      "Iteration: 12  Loss: 0.13280615210533142  Accuracy: 95 %\n",
      "Current Epoch: 12\n",
      "Iteration: 13  Loss: 0.13536661863327026  Accuracy: 95 %\n",
      "Current Epoch: 13\n",
      "Iteration: 14  Loss: 0.13606491684913635  Accuracy: 96 %\n",
      "Current Epoch: 14\n",
      "Iteration: 15  Loss: 0.13433565199375153  Accuracy: 96 %\n",
      "Current Epoch: 15\n",
      "Iteration: 16  Loss: 0.13238902390003204  Accuracy: 96 %\n",
      "Current Epoch: 16\n",
      "Iteration: 17  Loss: 0.12962941825389862  Accuracy: 96 %\n",
      "Current Epoch: 17\n",
      "Iteration: 18  Loss: 0.12696857750415802  Accuracy: 96 %\n",
      "Current Epoch: 18\n",
      "Iteration: 19  Loss: 0.12435351312160492  Accuracy: 96 %\n",
      "Current Epoch: 19\n",
      "Iteration: 20  Loss: 0.12298344075679779  Accuracy: 96 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1182e2438>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #  training model \n",
    "model.apply(weights_init)\n",
    "num_epochs = 20\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "n_classes = 2\n",
    "for epoch in range(num_epochs):\n",
    "    print('Current Epoch: {}'.format(epoch))\n",
    "    for i, (samples, targets) in enumerate(train_loader):\n",
    "        \n",
    "        train = Variable(samples.view(batch_size,1,-1))\n",
    "        targets = Variable(targets.type(torch.LongTensor))\n",
    "        \n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #setting up model for training\n",
    "        model.train()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        outputs = outputs.reshape(batch_size,2)\n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    count += 1\n",
    "    #accuracy at the end of epoch    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Predict test dataset\n",
    "    for samples, labels in val_loader:\n",
    "\n",
    "        test = Variable(samples.view(batch_size_val,1,-1))\n",
    "\n",
    "        #setting up in test mode\n",
    "        model.eval()\n",
    "        # Forward propagation\n",
    "        outputs = model(test)\n",
    "        outputs = outputs.view(batch_size_val, n_classes)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        predicted = torch.max(outputs.data, 1)[1].type(torch.FloatTensor)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += len(labels)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100 * correct / float(total)\n",
    "\n",
    "    loss_list.append(loss.data)\n",
    "    iteration_list.append(count)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "\n",
    "    print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('Final Loss curve')\n",
    "plt.plot(loss_list)\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('Final Validation Curve')\n",
    "plt.plot(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saivineethks/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ConvNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model,'model_su_vw_time_warped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_su_vw_time_warped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing with time warping of different sigma values other than trained ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_vw_targets_numpy = vw_targets_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vw FeaturesNumpy Output shape after time warping for testings\n",
      "(231, 50000)\n",
      "vw TargetsNumpy Output shape after time warping for testing\n",
      "(231,)\n"
     ]
    }
   ],
   "source": [
    "#implementation of time warping\n",
    "def GenerateRandomCurves(X, sigma=0.2, knot=4):\n",
    "    xx = (np.ones((X.shape[1],1))*(np.arange(0,X.shape[0], (X.shape[0]-1)/(knot+1)))).transpose()\n",
    "    yy = np.random.normal(loc=1.0, scale=sigma, size=(knot+2, X.shape[1]))\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    cs_x = CubicSpline(xx[:,0], yy[:,0])\n",
    "    cs_y = CubicSpline(xx[:,1], yy[:,1])\n",
    "    cs_z = CubicSpline(xx[:,2], yy[:,2])\n",
    "    return np.array([cs_x(x_range),cs_y(x_range),cs_z(x_range)]).transpose()\n",
    "\n",
    "def DistortTimesteps(X, sigma=0.2):\n",
    "    tt = GenerateRandomCurves(X, sigma) # Regard these samples aroun 1 as time intervals\n",
    "    tt_cum = np.cumsum(tt, axis=0)        # Add intervals to make a cumulative graph\n",
    "    # Make the last value to have X.shape[0]\n",
    "    t_scale = [(X.shape[0]-1)/tt_cum[-1,0],(X.shape[0]-1)/tt_cum[-1,1],(X.shape[0]-1)/tt_cum[-1,2]]\n",
    "    tt_cum[:,0] = tt_cum[:,0]*t_scale[0]\n",
    "    tt_cum[:,1] = tt_cum[:,1]*t_scale[1]\n",
    "    tt_cum[:,2] = tt_cum[:,2]*t_scale[2]\n",
    "    return tt_cum\n",
    "\n",
    "def DA_TimeWarp(X, sigma=0.2):\n",
    "    tt_new = DistortTimesteps(X, sigma)\n",
    "    X_new = np.zeros(X.shape)\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    X_new[:,0] = np.interp(x_range, tt_new[:,0], X[:,0])\n",
    "    X_new[:,1] = np.interp(x_range, tt_new[:,1], X[:,1])\n",
    "    X_new[:,2] = np.interp(x_range, tt_new[:,2], X[:,2])\n",
    "    return X_new\n",
    "\n",
    "\n",
    "vw_features_numpy_new = vw_features_numpy.T\n",
    "\n",
    "n_sets_time_warping = 10\n",
    "sigmas = [0.3,0.15,0.1,0.25,0.2,0.05,0.27,0.37,0.43,0.13]\n",
    "# sigmas = [0.22, 0.47, 0.33, 0.03, 0.19]\n",
    "\n",
    "for j in range (n_sets_time_warping):\n",
    "    for i in range(0,21,3):\n",
    "        ip = vw_features_numpy_new[:,i:i+3]\n",
    "        vw_features_numpy = np.append(vw_features_numpy, DA_TimeWarp(ip, sigmas[j]).T , axis = 0)\n",
    "    vw_targets_numpy = np.append(vw_targets_numpy,initial_vw_targets_numpy,axis = 0)\n",
    "# targets_numpy = np.repeat(targets_numpy, n_sets_time_warping+1)\n",
    "\n",
    "print('vw FeaturesNumpy Output shape after time warping for testings')\n",
    "print(vw_features_numpy.shape)\n",
    "print('vw TargetsNumpy Output shape after time warping for testing')\n",
    "print(vw_targets_numpy.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset dimensions\n",
      "Shape of Features Dataset\n",
      "torch.Size([126, 50000])\n",
      "Shape of Targets Dataset\n",
      "torch.Size([126])\n"
     ]
    }
   ],
   "source": [
    "vw_features = torch.from_numpy(vw_features_numpy).type(torch.FloatTensor)\n",
    "vw_targets = torch.from_numpy(vw_targets_numpy).type(torch.FloatTensor)\n",
    "\n",
    "vw_totalDataset = torch.utils.data.TensorDataset(vw_features,vw_targets)\n",
    "\n",
    "batch_size_test = 42\n",
    "vw_test_loader = torch.utils.data.DataLoader(vw_totalDataset, batch_size = batch_size_test, shuffle = False)\n",
    "\n",
    "\n",
    "print('Testing dataset dimensions')\n",
    "print('Shape of Features Dataset')\n",
    "print(vw_features.size())\n",
    "print('Shape of Targets Dataset')\n",
    "print(vw_targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100  21]\n",
      " [ 21  89]]\n",
      "Accuracy Score: 81.81818181818183\n",
      "F1 Score: 80.9090909090909\n",
      "Precision Score: 80.9090909090909\n",
      "Recall Score: 80.9090909090909\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "n_classes = 2\n",
    "accuracy_list = []\n",
    "f1_score_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "y_pred =[]\n",
    "y_true = []\n",
    "\n",
    "# batch_size_val = 16\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(vw_test_loader, 0):\n",
    "            samples, labels = data\n",
    "            samples = Variable(samples.view(batch_size_test,1,-1))\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            outputs = model(samples)\n",
    "            outputs = outputs.view(batch_size_test, n_classes)\n",
    "            \n",
    "            predictions = torch.argmax(outputs, 1)\n",
    "            targets = labels\n",
    "            \n",
    "            y_pred.extend(predictions)\n",
    "            y_true.extend(targets)\n",
    "\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy Score: {}\".format(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"F1 Score: {}\". format(f1_score(y_true, y_pred) * 100))\n",
    "print(\"Precision Score: {}\".format(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Recall Score: {}\".format(recall_score(y_true, y_pred)* 100))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vw FeaturesNumpy Output shape after time warping for testings\n",
      "(126, 50000)\n",
      "vw TargetsNumpy Output shape after time warping for testing\n",
      "(126,)\n"
     ]
    }
   ],
   "source": [
    "#implementation of time warping\n",
    "def GenerateRandomCurves(X, sigma=0.2, knot=4):\n",
    "    xx = (np.ones((X.shape[1],1))*(np.arange(0,X.shape[0], (X.shape[0]-1)/(knot+1)))).transpose()\n",
    "    yy = np.random.normal(loc=1.0, scale=sigma, size=(knot+2, X.shape[1]))\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    cs_x = CubicSpline(xx[:,0], yy[:,0])\n",
    "    cs_y = CubicSpline(xx[:,1], yy[:,1])\n",
    "    cs_z = CubicSpline(xx[:,2], yy[:,2])\n",
    "    return np.array([cs_x(x_range),cs_y(x_range),cs_z(x_range)]).transpose()\n",
    "\n",
    "def DistortTimesteps(X, sigma=0.2):\n",
    "    tt = GenerateRandomCurves(X, sigma) # Regard these samples aroun 1 as time intervals\n",
    "    tt_cum = np.cumsum(tt, axis=0)        # Add intervals to make a cumulative graph\n",
    "    # Make the last value to have X.shape[0]\n",
    "    t_scale = [(X.shape[0]-1)/tt_cum[-1,0],(X.shape[0]-1)/tt_cum[-1,1],(X.shape[0]-1)/tt_cum[-1,2]]\n",
    "    tt_cum[:,0] = tt_cum[:,0]*t_scale[0]\n",
    "    tt_cum[:,1] = tt_cum[:,1]*t_scale[1]\n",
    "    tt_cum[:,2] = tt_cum[:,2]*t_scale[2]\n",
    "    return tt_cum\n",
    "\n",
    "def DA_TimeWarp(X, sigma=0.2):\n",
    "    tt_new = DistortTimesteps(X, sigma)\n",
    "    X_new = np.zeros(X.shape)\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    X_new[:,0] = np.interp(x_range, tt_new[:,0], X[:,0])\n",
    "    X_new[:,1] = np.interp(x_range, tt_new[:,1], X[:,1])\n",
    "    X_new[:,2] = np.interp(x_range, tt_new[:,2], X[:,2])\n",
    "    return X_new\n",
    "\n",
    "\n",
    "vw_features_numpy_new = vw_features_numpy.T\n",
    "\n",
    "n_sets_time_warping = 5\n",
    "# sigmas = [0.3,0.15,0.1,0.25,0.2,0.05,0.27,0.37,0.43,0.13]\n",
    "sigmas = [0.22, 0.47, 0.33, 0.03, 0.19]\n",
    "\n",
    "for j in range (n_sets_time_warping):\n",
    "    for i in range(0,21,3):\n",
    "        ip = vw_features_numpy_new[:,i:i+3]\n",
    "        vw_features_numpy = np.append(vw_features_numpy, DA_TimeWarp(ip, sigmas[j]).T , axis = 0)\n",
    "    vw_targets_numpy = np.append(vw_targets_numpy,initial_vw_targets_numpy,axis = 0)\n",
    "\n",
    "\n",
    "print('vw FeaturesNumpy Output shape after time warping for testings')\n",
    "print(vw_features_numpy.shape)\n",
    "print('vw TargetsNumpy Output shape after time warping for testing')\n",
    "print(vw_targets_numpy.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56 10]\n",
      " [ 4 56]]\n",
      "Accuracy Score: 88.88888888888889\n",
      "F1 Score: 88.8888888888889\n",
      "Precision Score: 84.84848484848484\n",
      "Recall Score: 93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "n_classes = 2\n",
    "accuracy_list = []\n",
    "f1_score_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "y_pred =[]\n",
    "y_true = []\n",
    "\n",
    "# batch_size_val = 16\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(vw_test_loader, 0):\n",
    "            samples, labels = data\n",
    "            samples = Variable(samples.view(batch_size_test,1,-1))\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            outputs = model(samples)\n",
    "            outputs = outputs.view(batch_size_test, n_classes)\n",
    "            \n",
    "            predictions = torch.argmax(outputs, 1)\n",
    "            targets = labels\n",
    "            \n",
    "            y_pred.extend(predictions)\n",
    "            y_true.extend(targets)\n",
    "\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy Score: {}\".format(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"F1 Score: {}\". format(f1_score(y_true, y_pred) * 100))\n",
    "print(\"Precision Score: {}\".format(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Recall Score: {}\".format(recall_score(y_true, y_pred)* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
