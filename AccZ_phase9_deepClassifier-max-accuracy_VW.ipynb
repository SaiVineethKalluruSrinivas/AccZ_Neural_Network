{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50001)\n",
      "[0.04913539 0.0478669  0.05771144 ... 0.16863332 0.05331072 0.04423187]\n",
      "(50000,)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "data = sio.loadmat('../SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "\n",
    "\n",
    "class AccZDataset(Dataset):\n",
    "    def __init__(self,start_no,range_len):\n",
    "        data = sio.loadmat('../SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "        self.start_no = start_no\n",
    "        self.range_len = range_len\n",
    "        self.data_set = data['L23MatChunk']\n",
    "        self.n_trails = len(self.data_set)\n",
    "        self.train_set = np.zeros((1,50000))\n",
    "        \n",
    "        for i in range (0,self.n_trails):\n",
    "            curr = np.asarray(self.data_set[i][0][0][self.start_no : self.start_no+self.range_len]).reshape(1,self.range_len)\n",
    "            self.train_set = np.append(self.train_set, curr, axis = 0)\n",
    "\n",
    "        self.train_set = np.delete(self.train_set, (0), axis=0) #array of 20 * 50000\n",
    "        \n",
    "        labels = []\n",
    "        for i in range(0, self.n_trails):\n",
    "            if(i < 10):\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "        \n",
    "        labels = np.asarray(labels).reshape(self.n_trails,1)\n",
    "        self.train_set = np.append(self.train_set, labels, axis = 1)\n",
    "        print(self.train_set.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.train_set[idx][:-1]\n",
    "        label = self.train_set[idx][-1]\n",
    "\n",
    "        return sample, label \n",
    "\n",
    "\n",
    "\n",
    "dataset = AccZDataset(20,50000)\n",
    "real_value, real_label = dataset[13]\n",
    "print(real_value)\n",
    "print(real_value.shape)\n",
    "print(real_label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50001)\n"
     ]
    }
   ],
   "source": [
    "#DATASET PREPERATION\n",
    "\n",
    "\n",
    "data = sio.loadmat('../SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "start_no = 0\n",
    "range_len = 50000\n",
    "data_set = data['L23MatChunk']\n",
    "n_trials = len(data_set)\n",
    "total_set = np.zeros((1,50000))\n",
    "\n",
    "for i in range (20):\n",
    "\n",
    "    curr = np.asarray(data_set[i][0][0][start_no : start_no+range_len]).reshape(1,range_len)\n",
    "    total_set = np.append(total_set, curr, axis = 0)\n",
    "\n",
    "total_set = np.delete(total_set, (0), axis=0) \n",
    "\n",
    "labels = []\n",
    "for i in range(0, n_trials):\n",
    "    if(i < 10):\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "\n",
    "labels = np.asarray(labels).reshape(n_trials,1)\n",
    "total_set = np.append(total_set, labels, axis = 1)\n",
    "print(total_set.shape)\n",
    "targets_numpy = total_set[:,-1]\n",
    "features_numpy = total_set[:,:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50001)\n"
     ]
    }
   ],
   "source": [
    "vw_data = sio.loadmat('../VWVW_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "vw_start_no = 0\n",
    "vw_range_len = 50000\n",
    "vw_data_set = data['L23MatChunk']\n",
    "vw_n_trials = len(data_set)\n",
    "vw_total_set = np.zeros((1,50000))\n",
    "\n",
    "for i in range (20):\n",
    "\n",
    "    vw_curr = np.asarray(vw_data_set[i][0][0][vw_start_no : vw_start_no + vw_range_len]).reshape(1,vw_range_len)\n",
    "    vw_total_set = np.append(vw_total_set, vw_curr, axis = 0)\n",
    "\n",
    "vw_total_set = np.delete(vw_total_set, (0), axis=0) \n",
    "\n",
    "vw_labels = []\n",
    "for i in range(0, vw_n_trials):\n",
    "    if(i < 10):\n",
    "        vw_labels.append(0)\n",
    "    else:\n",
    "        vw_labels.append(1)\n",
    "\n",
    "vw_labels = np.asarray(vw_labels).reshape(vw_n_trials,1)\n",
    "vw_total_set = np.append(vw_total_set, vw_labels, axis = 1)\n",
    "print(vw_total_set.shape)\n",
    "vw_targets_numpy = vw_total_set[:,-1]\n",
    "vw_features_numpy = vw_total_set[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FeaturesNumpy Database\n",
      "(20, 50000)\n",
      "Original TargetsNumpy Database\n",
      "(20,)\n",
      "FeaturesNumpy Output shape after jittering\n",
      "(460, 50000)\n",
      "TargetsNumpy Output shape after jittering\n",
      "(460,)\n",
      "FeaturesNumpy Output shape after magwarping\n",
      "(900, 50000)\n",
      "TargetsNumpy Output shape after magwarping\n",
      "(900,)\n",
      "[[1.22414497 1.22158544 1.24027217 ... 1.25914105 1.24361916 1.24150394]]\n",
      "FeaturesNumpy Output shape after rotation\n",
      "(1340, 50000)\n",
      "TargetsNumpy Output shape after rotation\n",
      "(1340,)\n"
     ]
    }
   ],
   "source": [
    "#DATA AUGMENTATION\n",
    "#SINGLE KERNEL \n",
    "\n",
    "# import axangles\n",
    "from scipy.interpolate import CubicSpline\n",
    "from transforms3d.axangles import axangle2mat\n",
    "\n",
    "features_numpy_new = features_numpy.T\n",
    "\n",
    "print('Original FeaturesNumpy Database')\n",
    "print(features_numpy.shape)\n",
    "print('Original TargetsNumpy Database')\n",
    "print(targets_numpy.shape)\n",
    "\n",
    "\n",
    "#perform jittering\n",
    "def DA_Jitter(X, sigma= 0.05):\n",
    "    myNoise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n",
    "    return X+myNoise\n",
    "\n",
    "#perform scaling\n",
    "def DA_Scaling(X, sigma=0.1):\n",
    "    scalingFactor = np.random.normal(loc=1.0, scale=sigma, size=(1,X.shape[1])) # shape=(1,3)\n",
    "    myNoise = np.matmul(np.ones((X.shape[0],1)), scalingFactor)\n",
    "    return X*myNoise\n",
    "\n",
    "#perform magnitude warping \n",
    "def GenerateRandomCurves(X, sigma=0.2, knot=4):\n",
    "    xx = (np.ones((X.shape[1],1))*(np.arange(0,X.shape[0], (X.shape[0]-1)/(knot+1)))).transpose()\n",
    "    yy = np.random.normal(loc=1.0, scale=sigma, size=(knot+2, X.shape[1]))\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    cs_x = CubicSpline(xx[:,0], yy[:,0])\n",
    "    return np.array([cs_x(x_range)]).transpose()\n",
    "\n",
    "def DA_MagWarp(X, sigma):\n",
    "    return X * GenerateRandomCurves(X, sigma)\n",
    "\n",
    "#performing Rotation\n",
    "percent_value = 1\n",
    "percent_shift = (range_len / 100) * percent_value\n",
    "def DA_Rotation(X):\n",
    "    shift = np.random.randint(low=0 , high = percent_shift) #giving percent_value shift (if percent_value is 1, then 1% shift)\n",
    "    return np.roll(X, shift)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#implement jittering\n",
    "n_sets_jitter = 22\n",
    "sigma = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,0.5,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.31,0.57]\n",
    "#number of values in sigma list should match the n_sets_jitter value\n",
    "for j in range (n_sets_jitter):\n",
    "    for i in range(20):\n",
    "        features_numpy = np.append(features_numpy, DA_Jitter(features_numpy_new[:,i], sigma[j]).reshape(1,-1), axis = 0)\n",
    "    targets_numpy = np.append(targets_numpy, targets_numpy[0:20], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "print('FeaturesNumpy Output shape after jittering')\n",
    "print(features_numpy.shape)\n",
    "print('TargetsNumpy Output shape after jittering')\n",
    "print(targets_numpy.shape)\n",
    "\n",
    "# #implement scaling\n",
    "# features_numpy_new = features_numpy.T\n",
    "# n_sets_scaling = 22\n",
    "# sigma = [0.2,0.5,0.3,0.4,0.2,0.6,0.8,0.9,0.1,0.7,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.31,0.57,0.73]\n",
    "\n",
    "\n",
    "# for j in range (n_sets_scaling):\n",
    "#     for i in range(20):\n",
    "#         features_numpy = np.append(features_numpy, DA_Scaling(features_numpy_new[:,0].reshape(-1,1), sigma[j]).reshape(1,-1), axis = 0)\n",
    "#     targets_numpy = np.append(targets_numpy, targets_numpy[0:20], axis = 0)\n",
    "    \n",
    "\n",
    "# print('FeaturesNumpy Output shape after scaling')\n",
    "# print(features_numpy.shape)\n",
    "# print('TargetsNumpy Output shape after scaling')\n",
    "# print(targets_numpy.shape)\n",
    "\n",
    "\n",
    "#implement magnitude warping\n",
    "features_numpy_new = features_numpy.T\n",
    "n_sets_magwarp = 22\n",
    "sigma = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,0.5,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.31,0.57]\n",
    "#number of values in sigma list should match the n_sets_jitter value\n",
    "for j in range (n_sets_magwarp):\n",
    "    for i in range(20):\n",
    "        features_numpy = np.append(features_numpy, DA_MagWarp(features_numpy_new[:,i].reshape(-1,1), sigma[j]).reshape(1,-1), axis = 0)\n",
    "    targets_numpy = np.append(targets_numpy, targets_numpy[0:20], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "print('FeaturesNumpy Output shape after magwarping')\n",
    "print(features_numpy.shape)\n",
    "print('TargetsNumpy Output shape after magwarping')\n",
    "print(targets_numpy.shape)\n",
    "\n",
    "#implement Rotation\n",
    "features_numpy_new = features_numpy.T\n",
    "n_sets_rotation = 22\n",
    "\n",
    "\n",
    "print(DA_Rotation(features_numpy_new[:,i].reshape(-1,1)).reshape(1,-1))\n",
    "\n",
    "for j in range (n_sets_rotation):\n",
    "    for i in range(20):\n",
    "        features_numpy = np.append(features_numpy, DA_Rotation(features_numpy_new[:,i].reshape(-1,1)).reshape(1,-1), axis = 0)\n",
    "    targets_numpy = np.append(targets_numpy, targets_numpy[0:20], axis = 0)\n",
    "\n",
    "\n",
    "print('FeaturesNumpy Output shape after rotation')\n",
    "print(features_numpy.shape)\n",
    "print('TargetsNumpy Output shape after rotation')\n",
    "print(targets_numpy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Features Train Dataset\n",
      "torch.Size([1072, 50000])\n",
      "Shape of Targets Train Dataset\n",
      "torch.Size([1072])\n",
      "Shape of Features Test Dataset\n",
      "torch.Size([268, 50000])\n",
      "Shape of Targets Test Dataset\n",
      "torch.Size([268])\n"
     ]
    }
   ],
   "source": [
    "#TRAIN AND TEST SPLIT\n",
    "\n",
    "\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "featuresTrain = torch.from_numpy(features_train).type(torch.FloatTensor)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.FloatTensor)\n",
    "\n",
    "featuresTest = torch.from_numpy(features_test).type(torch.FloatTensor)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.FloatTensor)\n",
    "\n",
    "vw_featuresTest = torch.from_numpy(features_test).type(torch.FloatTensor)\n",
    "vw_targetsTest = torch.from_numpy(targets_test).type(torch.FloatTensor)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "vw_test = torch.utils.data.TensorDataset(vw_featuresTest,vw_targetsTest)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "batch_size_test = 4\n",
    "batch_size_val = 4\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size_test, shuffle = False)\n",
    "vw_test_loader = torch.utils.data.DataLoader(vw_test, batch_size = batch_size_val, shuffle = False)\n",
    "\n",
    "\n",
    "print('Shape of Features Train Dataset')\n",
    "print(featuresTrain.size())\n",
    "print('Shape of Targets Train Dataset')\n",
    "print(targetsTrain.size())\n",
    "print('Shape of Features Test Dataset')\n",
    "print(featuresTest.size())\n",
    "print('Shape of Targets Test Dataset')\n",
    "print(targetsTest.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv1d(1, 1, kernel_size=(25,), stride=(10,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1d(1, 1, kernel_size=(10,), stride=(5,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1d(1, 1, kernel_size=(10,), stride=(3,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (avgLayer): AvgPool1d(kernel_size=(10,), stride=(2,), padding=(0,))\n",
       "  (fc1): Linear(in_features=161, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Designing the model\n",
    "\n",
    "filters = 1\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 1, out_channels = filters,kernel_size=25, stride=10),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(filters))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = filters, out_channels = filters, kernel_size=10, stride=5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(filters))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = filters, out_channels = filters, kernel_size=10, stride=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(filters))\n",
    "        self.avgLayer = nn.AvgPool1d(10, stride = 2)\n",
    "        self.fc1 = nn.Linear(161,2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out) \n",
    "        out = self.avgLayer(out)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        return Variable(hidden)\n",
    "    \n",
    "    \n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        torch.nn.init.xavier_uniform(m.weight.data, nn.init.calculate_gain('relu'))\n",
    "        m.bias.data.zero_()\n",
    "    \n",
    "\n",
    "model = ConvNet()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saivineethks/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch: 0\n",
      "Current Batch Number: 1\n",
      "Current Batch Number: 2\n",
      "Current Batch Number: 3\n",
      "Current Batch Number: 4\n",
      "Current Batch Number: 5\n",
      "Current Batch Number: 6\n",
      "Current Batch Number: 7\n",
      "Current Batch Number: 8\n",
      "Current Batch Number: 9\n",
      "Current Batch Number: 10\n",
      "Current Batch Number: 11\n",
      "Current Batch Number: 12\n",
      "Current Batch Number: 13\n",
      "Current Batch Number: 14\n",
      "Current Batch Number: 15\n",
      "Current Batch Number: 16\n",
      "Current Batch Number: 17\n",
      "Current Batch Number: 18\n",
      "Current Batch Number: 19\n",
      "Current Batch Number: 20\n",
      "Current Batch Number: 21\n",
      "Current Batch Number: 22\n",
      "Current Batch Number: 23\n",
      "Current Batch Number: 24\n",
      "Current Batch Number: 25\n",
      "Current Batch Number: 26\n",
      "Current Batch Number: 27\n",
      "Current Batch Number: 28\n",
      "Current Batch Number: 29\n",
      "Current Batch Number: 30\n",
      "Current Batch Number: 31\n",
      "Current Batch Number: 32\n",
      "Current Batch Number: 33\n",
      "Current Batch Number: 34\n",
      "Current Batch Number: 35\n",
      "Current Batch Number: 36\n",
      "Current Batch Number: 37\n",
      "Current Batch Number: 38\n",
      "Current Batch Number: 39\n",
      "Current Batch Number: 40\n",
      "Current Batch Number: 41\n",
      "Current Batch Number: 42\n",
      "Current Batch Number: 43\n",
      "Current Batch Number: 44\n",
      "Current Batch Number: 45\n",
      "Current Batch Number: 46\n",
      "Current Batch Number: 47\n",
      "Current Batch Number: 48\n",
      "Current Batch Number: 49\n",
      "Current Batch Number: 50\n",
      "Current Batch Number: 51\n",
      "Current Batch Number: 52\n",
      "Current Batch Number: 53\n",
      "Current Batch Number: 54\n",
      "Current Batch Number: 55\n",
      "Current Batch Number: 56\n",
      "Current Batch Number: 57\n",
      "Current Batch Number: 58\n",
      "Current Batch Number: 59\n",
      "Current Batch Number: 60\n",
      "Current Batch Number: 61\n",
      "Current Batch Number: 62\n",
      "Current Batch Number: 63\n",
      "Current Batch Number: 64\n",
      "Current Batch Number: 65\n",
      "Current Batch Number: 66\n",
      "Current Batch Number: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saivineethks/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1  Loss: 0.02835977077484131  Accuracy: 54 %\n",
      "Current Epoch: 1\n",
      "Current Batch Number: 1\n",
      "Current Batch Number: 2\n",
      "Current Batch Number: 3\n",
      "Current Batch Number: 4\n",
      "Current Batch Number: 5\n",
      "Current Batch Number: 6\n",
      "Current Batch Number: 7\n",
      "Current Batch Number: 8\n",
      "Current Batch Number: 9\n",
      "Current Batch Number: 10\n",
      "Current Batch Number: 11\n",
      "Current Batch Number: 12\n",
      "Current Batch Number: 13\n",
      "Current Batch Number: 14\n",
      "Current Batch Number: 15\n",
      "Current Batch Number: 16\n",
      "Current Batch Number: 17\n",
      "Current Batch Number: 18\n",
      "Current Batch Number: 19\n",
      "Current Batch Number: 20\n",
      "Current Batch Number: 21\n",
      "Current Batch Number: 22\n",
      "Current Batch Number: 23\n",
      "Current Batch Number: 24\n",
      "Current Batch Number: 25\n",
      "Current Batch Number: 26\n",
      "Current Batch Number: 27\n",
      "Current Batch Number: 28\n",
      "Current Batch Number: 29\n",
      "Current Batch Number: 30\n",
      "Current Batch Number: 31\n",
      "Current Batch Number: 32\n",
      "Current Batch Number: 33\n",
      "Current Batch Number: 34\n",
      "Current Batch Number: 35\n",
      "Current Batch Number: 36\n",
      "Current Batch Number: 37\n",
      "Current Batch Number: 38\n",
      "Current Batch Number: 39\n",
      "Current Batch Number: 40\n",
      "Current Batch Number: 41\n",
      "Current Batch Number: 42\n",
      "Current Batch Number: 43\n",
      "Current Batch Number: 44\n",
      "Current Batch Number: 45\n",
      "Current Batch Number: 46\n",
      "Current Batch Number: 47\n",
      "Current Batch Number: 48\n",
      "Current Batch Number: 49\n",
      "Current Batch Number: 50\n",
      "Current Batch Number: 51\n",
      "Current Batch Number: 52\n",
      "Current Batch Number: 53\n",
      "Current Batch Number: 54\n",
      "Current Batch Number: 55\n",
      "Current Batch Number: 56\n",
      "Current Batch Number: 57\n",
      "Current Batch Number: 58\n",
      "Current Batch Number: 59\n",
      "Current Batch Number: 60\n",
      "Current Batch Number: 61\n",
      "Current Batch Number: 62\n",
      "Current Batch Number: 63\n",
      "Current Batch Number: 64\n",
      "Current Batch Number: 65\n",
      "Current Batch Number: 66\n",
      "Current Batch Number: 67\n",
      "Iteration: 2  Loss: 0.024594968184828758  Accuracy: 99 %\n",
      "Current Epoch: 2\n",
      "Current Batch Number: 1\n",
      "Current Batch Number: 2\n",
      "Current Batch Number: 3\n",
      "Current Batch Number: 4\n",
      "Current Batch Number: 5\n",
      "Current Batch Number: 6\n",
      "Current Batch Number: 7\n",
      "Current Batch Number: 8\n",
      "Current Batch Number: 9\n",
      "Current Batch Number: 10\n",
      "Current Batch Number: 11\n",
      "Current Batch Number: 12\n",
      "Current Batch Number: 13\n",
      "Current Batch Number: 14\n",
      "Current Batch Number: 15\n",
      "Current Batch Number: 16\n",
      "Current Batch Number: 17\n",
      "Current Batch Number: 18\n",
      "Current Batch Number: 19\n",
      "Current Batch Number: 20\n",
      "Current Batch Number: 21\n",
      "Current Batch Number: 22\n",
      "Current Batch Number: 23\n",
      "Current Batch Number: 24\n",
      "Current Batch Number: 25\n",
      "Current Batch Number: 26\n",
      "Current Batch Number: 27\n",
      "Current Batch Number: 28\n",
      "Current Batch Number: 29\n",
      "Current Batch Number: 30\n",
      "Current Batch Number: 31\n",
      "Current Batch Number: 32\n",
      "Current Batch Number: 33\n",
      "Current Batch Number: 34\n",
      "Current Batch Number: 35\n",
      "Current Batch Number: 36\n",
      "Current Batch Number: 37\n",
      "Current Batch Number: 38\n",
      "Current Batch Number: 39\n",
      "Current Batch Number: 40\n",
      "Current Batch Number: 41\n",
      "Current Batch Number: 42\n",
      "Current Batch Number: 43\n",
      "Current Batch Number: 44\n",
      "Current Batch Number: 45\n",
      "Current Batch Number: 46\n",
      "Current Batch Number: 47\n",
      "Current Batch Number: 48\n",
      "Current Batch Number: 49\n",
      "Current Batch Number: 50\n",
      "Current Batch Number: 51\n",
      "Current Batch Number: 52\n",
      "Current Batch Number: 53\n",
      "Current Batch Number: 54\n",
      "Current Batch Number: 55\n",
      "Current Batch Number: 56\n",
      "Current Batch Number: 57\n",
      "Current Batch Number: 58\n",
      "Current Batch Number: 59\n",
      "Current Batch Number: 60\n",
      "Current Batch Number: 61\n",
      "Current Batch Number: 62\n",
      "Current Batch Number: 63\n",
      "Current Batch Number: 64\n",
      "Current Batch Number: 65\n",
      "Current Batch Number: 66\n",
      "Current Batch Number: 67\n",
      "Iteration: 3  Loss: 0.01194709911942482  Accuracy: 98 %\n",
      "Current Epoch: 3\n",
      "Current Batch Number: 1\n",
      "Current Batch Number: 2\n",
      "Current Batch Number: 3\n",
      "Current Batch Number: 4\n",
      "Current Batch Number: 5\n",
      "Current Batch Number: 6\n",
      "Current Batch Number: 7\n",
      "Current Batch Number: 8\n",
      "Current Batch Number: 9\n",
      "Current Batch Number: 10\n",
      "Current Batch Number: 11\n",
      "Current Batch Number: 12\n",
      "Current Batch Number: 13\n",
      "Current Batch Number: 14\n",
      "Current Batch Number: 15\n",
      "Current Batch Number: 16\n",
      "Current Batch Number: 17\n",
      "Current Batch Number: 18\n",
      "Current Batch Number: 19\n",
      "Current Batch Number: 20\n",
      "Current Batch Number: 21\n",
      "Current Batch Number: 22\n",
      "Current Batch Number: 23\n",
      "Current Batch Number: 24\n",
      "Current Batch Number: 25\n",
      "Current Batch Number: 26\n",
      "Current Batch Number: 27\n",
      "Current Batch Number: 28\n",
      "Current Batch Number: 29\n",
      "Current Batch Number: 30\n",
      "Current Batch Number: 31\n",
      "Current Batch Number: 32\n",
      "Current Batch Number: 33\n",
      "Current Batch Number: 34\n",
      "Current Batch Number: 35\n",
      "Current Batch Number: 36\n",
      "Current Batch Number: 37\n",
      "Current Batch Number: 38\n",
      "Current Batch Number: 39\n",
      "Current Batch Number: 40\n",
      "Current Batch Number: 41\n",
      "Current Batch Number: 42\n",
      "Current Batch Number: 43\n",
      "Current Batch Number: 44\n",
      "Current Batch Number: 45\n",
      "Current Batch Number: 46\n",
      "Current Batch Number: 47\n",
      "Current Batch Number: 48\n",
      "Current Batch Number: 49\n",
      "Current Batch Number: 50\n",
      "Current Batch Number: 51\n",
      "Current Batch Number: 52\n",
      "Current Batch Number: 53\n",
      "Current Batch Number: 54\n",
      "Current Batch Number: 55\n",
      "Current Batch Number: 56\n",
      "Current Batch Number: 57\n",
      "Current Batch Number: 58\n",
      "Current Batch Number: 59\n",
      "Current Batch Number: 60\n",
      "Current Batch Number: 61\n",
      "Current Batch Number: 62\n",
      "Current Batch Number: 63\n",
      "Current Batch Number: 64\n",
      "Current Batch Number: 65\n",
      "Current Batch Number: 66\n",
      "Current Batch Number: 67\n",
      "Iteration: 4  Loss: 0.005951128900051117  Accuracy: 99 %\n",
      "Current Epoch: 4\n",
      "Current Batch Number: 1\n",
      "Current Batch Number: 2\n",
      "Current Batch Number: 3\n",
      "Current Batch Number: 4\n",
      "Current Batch Number: 5\n",
      "Current Batch Number: 6\n",
      "Current Batch Number: 7\n",
      "Current Batch Number: 8\n",
      "Current Batch Number: 9\n",
      "Current Batch Number: 10\n",
      "Current Batch Number: 11\n",
      "Current Batch Number: 12\n",
      "Current Batch Number: 13\n",
      "Current Batch Number: 14\n",
      "Current Batch Number: 15\n",
      "Current Batch Number: 16\n",
      "Current Batch Number: 17\n",
      "Current Batch Number: 18\n",
      "Current Batch Number: 19\n",
      "Current Batch Number: 20\n",
      "Current Batch Number: 21\n",
      "Current Batch Number: 22\n",
      "Current Batch Number: 23\n",
      "Current Batch Number: 24\n",
      "Current Batch Number: 25\n",
      "Current Batch Number: 26\n",
      "Current Batch Number: 27\n",
      "Current Batch Number: 28\n",
      "Current Batch Number: 29\n",
      "Current Batch Number: 30\n",
      "Current Batch Number: 31\n",
      "Current Batch Number: 32\n",
      "Current Batch Number: 33\n",
      "Current Batch Number: 34\n",
      "Current Batch Number: 35\n",
      "Current Batch Number: 36\n",
      "Current Batch Number: 37\n",
      "Current Batch Number: 38\n",
      "Current Batch Number: 39\n",
      "Current Batch Number: 40\n",
      "Current Batch Number: 41\n",
      "Current Batch Number: 42\n",
      "Current Batch Number: 43\n",
      "Current Batch Number: 44\n",
      "Current Batch Number: 45\n",
      "Current Batch Number: 46\n",
      "Current Batch Number: 47\n",
      "Current Batch Number: 48\n",
      "Current Batch Number: 49\n",
      "Current Batch Number: 50\n",
      "Current Batch Number: 51\n",
      "Current Batch Number: 52\n",
      "Current Batch Number: 53\n",
      "Current Batch Number: 54\n",
      "Current Batch Number: 55\n",
      "Current Batch Number: 56\n",
      "Current Batch Number: 57\n",
      "Current Batch Number: 58\n",
      "Current Batch Number: 59\n",
      "Current Batch Number: 60\n",
      "Current Batch Number: 61\n",
      "Current Batch Number: 62\n",
      "Current Batch Number: 63\n",
      "Current Batch Number: 64\n",
      "Current Batch Number: 65\n",
      "Current Batch Number: 66\n",
      "Current Batch Number: 67\n",
      "Iteration: 5  Loss: 0.0027111247181892395  Accuracy: 99 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x124ea0d68>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xl8VdW1wPHfys08QxISGcMQoICgECYHxKlSn4pW26J1oGLVttpWq7W277V28FVbx9Y+h4qCA05UK1q14oCgVSBhFBAI80xCGEKAjOv9cU6SyyWQG7jJndb388kn956zc87KSc46++y9z76iqhhjjIkOMcEOwBhjTPuxpG+MMVHEkr4xxkQRS/rGGBNFLOkbY0wUsaRvjDFRxJK+CQki0l1E9ouIJwDbmiIifwhEXMZEGkv6pl2JyHoROegm+Iavzqq6UVVTVbWujfc/UUQ+bct9GBPKYoMdgIlKF6vqB8EOIhyJiACiqvXBjsWEJ6vpm5AgIvkioiIS676fJSK/F5HPRKRCRN4XkWyv8q+JyHYR2Ssis0VkYABi6CwiM0SkXERKROT7XutGiEiRiOwTkR0i8pC7PFFEXhCRXSKyR0Tmi0juUbbfTUReF5FSt/xj7vJ7ROSFFo7FvSLyGXAAuFNEiny2fZuIzHBfJ4jIAyKy0Y31CRFJOtHjYyKDJX0Tyq4Cvgd0AuKBO7zWvQsUuOsWAC8GYH8vA5uBzsAVwP+KyDnuukeBR1U1HegNvOouvw7IALoBWcDNwEHfDbt9FW8DG4B8oIu7P39dA9wIpAFPAP1EpMBr/VXANPf1fUBf4BSgj7uvX7diXyaCWdI3wfBPt1a8R0T+eYxyz6rqKlU9iJNkT2lYoarPqGqFqlYB9wBDRCTjeAMSkW7A6cBdqnpIVRcBTwPXukVqgD4ikq2q+1X1C6/lWUAfVa1T1WJV3dfMLkbgXEzuVNVKdx+t6VuYoqrLVLVWVfcCbwJXurEXAP2BGW7zz43AbaparqoVwP8CE1qxLxPBLOmbYLhUVTPdr0uPUW671+sDQCo4tWYRuU9E1ojIPmC9Wyab49cZaEiSDTbg1JIBJuHUnr9ym3Aucpc/D/wbeFlEtorIn0QkrpntdwM2qGrtcca3yef9NNykj1PL/6eqHgBygGSguOHCCrznLjfGkr4JS1cB44HzcJpW8t3lcgLb3Ap0FJE0r2XdgS0AqrpaVa/EaU66H5guIimqWqOqv1XVAcBpwEU03R142wR0b2in91GJk6gb5DVTxnc63JlAjoicgpP8G5p2ynCalwZ6XVgzVDX16L+6iSaW9E04SgOqgF04yfJ/W/nz4nbANn6p6ibgP8Af3WWDcWr3L7g/cLWI5LijZva426kXkbNF5GS3zX4fTnNPcyNr5gHbgPtEJMXdx+nuukXAGPdZhQzg7pZ+AVWtAV4D/gx0xLkI4Mb3d+BhEenkxt5FRC5o5TEyEcqSvglHz+E0vWwBlgNfHLv4EU7DqQ03frk18Ctx7hq2Am8Av/EaWjoOWCYi+3E6dSe4fQ15wHSchL8C+ASnyecw7vMHF+N0rG7E6TD+jrtuJvAKsAQoxunw9cc0nLud13yaje4CSoAv3OavD4B+fm7TRDixD1ExxpjoYTV9Y4yJIpb0jTEmiljSN8aYKGJJ3xhjokjITbiWnZ2t+fn5wQ7DGGPCSnFxcZmqtvgQXsgl/fz8fIqKilouaIwxppGIbPCnnDXvGGNMFImYpK+q2DMHxhhzbCHXvHO81pTu51tPfE6/vDT65abRLy+dfnmpFOSmkZ7Y3PxXxhgTfSIm6XtiYrhgYB5fba/gteLNHKhu+tS9LplJ9M1NpW9eGv3z0uibm0bvnFQS407441iNMSasREzS75mdwn2XDwagvl7ZsucgK7dXsHJHBSu3V7BqRwWflpRRU+c0AXlihPysZPfOwLkr6JubRo+sFDwxJzJZozHGhK6ISfreYmKEbh2T6dYxmfMGNH1yXU1dPevKKhsvAl9tr2DZ1n28++V2GroDEmJjKMhNPexC0D8vndz0BJzPpzDGmPAVkUn/aOI8MfTNdZp3vB2ormX1jv2H3RXMWV3KPxZsbiyTkRRHv9w0+ualNvUZ5KaRkWz9BcaY8BFVSf9okuNjGdItkyHdMg9bXl5ZzaodTXcFq7ZX8ObCrVRUNc1im5ue4F4AUhsvBH06pZIUb/0FxpjQY0n/GDqmxDOqVxajemU1LlNVtu091HRX4PYbTF27i+pa57MzRCA/K4W+uamHjSTKz0oh1hMxo2SNMWHIkn4riQidM5PonJnE2f06NS6vratnQ/kBp/PYbSJaub2Cmct3UO/2F8R7YujdKbXprsDtM+iSmWT9BcaYdhFyH6JSWFiokTQNw6GaOkp27m+6ELgXg217DzWWSU2Ide4K3GcMnKGl6XRMiQ9i5MaYcCIixapa2FI5q+m3scQ4D4O6ZDCoS8Zhy/cerGF1Q1+B+/2dpdt5ad6mxjLZqQn0yzt8JFHf3DRSEuzPZow5PpY9giQjKY7C/I4U5ndsXKaqlFZUNV4IGp4zmDZvA4dqmj5ru1vHpCOGlPbMTiE+1voLjDHHZkk/hIgIndIT6ZSeyJi+TTOk1tUrm8oPsHKH03H8lfv945U7qXM7DGJjhF45KY0jiRouBl07JBFjD5sZY1yW9MOAJ0bIz04hPzuFCwbmNS6vqq1jbWnlYUNKF27czVuLtzaWSY73UJCbdtiFoG9eKjmp9rCZMdHIOnIjUMWhGlbv3O/cFXg1Fe2qrG4s0yE5jv556Vw7ugfjBuXZBcCYMGcduVEsLTGOod07MLR7h8OWl+2vOuxCMG9dOT94cQGje2Xxm0sG0D8vPUgRG2Pai9X0o1htXT0vzdvIgzNXse9gDVeP6sHt5/clM9mGihoTbvyt6dtwjygW64nhmtH5zLpjLFeP6sELX2xg7AOzeP7z9dTW1bf488aY8GNJ35CZHM/vxg/inZ+cydfy0vmfN5dx0V8/5fM1u4IdmjEmwCzpm0b989KZ9v2RPP7doVQcquXKv3/Bj15cwObdB4IdmjEmQCzpm8OICN84+SQ+/NlZ3H5+Xz78agfnPvgJD89cxUGvTyMzxoQnS/qmWYlxHn58bgEf/mws5w/I5dEPV3Pug7N4e8lW+wB6Y8KYJX1zTF0yk3jsqqG8cuMoMpLjuWXaQiY89QXLt+4LdmjGmONgSd/4ZWSvLN6+9QzuvWwQq3ZUcNFf5/CrN5ZS7vXAlzEm9FnSN37zxAjfHdmDWXeczbWj83l5/ibG/vljpny2zoZ4GhMmLOmbVstIjuOeSwby7k/OZHDXTO55azkX/mUOn5WUBTs0Y0wLLOmb49Y3N43nJ43gyWuGcbCmju8+PZebni9iU7kN8TQmVFnSNydERLhgYB4zbzuLOy/ox+xVZZz70Cc8+P5KDlTXtrwBY0y78ivpi8g4EVkpIiUi8otm1ieIyCvu+rkiku8uP19EikVkqfv9nMCGb0JFYpyHH53dh4/vGMuFg/L460clnPvgJ7y5aIsN8TQmhLSY9EXEA/wN+AYwALhSRAb4FJsE7FbVPsDDwP3u8jLgYlU9GbgOeD5QgZvQlJeRyCMTTmX6zaPJSo3nJy8v4ttPfs6XW/YGOzRjDP7V9EcAJaq6VlWrgZeB8T5lxgNT3dfTgXNFRFR1oao2fKLHMiBJRBICEbgJbYX5HXnzR2dw/+Uns7a0kosf+5S7X1/Crv1VwQ7NmKjmT9LvAmzyer/ZXdZsGVWtBfYCWT5lLgcWqOoRZ72I3CgiRSJSVFpa6m/sJsR5YoTvDO/OR3eM5frTe/Ja0WbGPjCLyZ+uo8aGeBoTFO3SkSsiA3GafG5qbr2qPqWqhapamJOT01wRE8YykuL4n4sG8N5Pz+TU7h34/dvL+cajc5i9yi7wxrQ3f5L+FqCb1/uu7rJmy4hILJAB7HLfdwXeAK5V1TUnGrAJX306pTH1e8N5+tpCaurqufaZedwwtYgNuyqDHZoxUcOfpD8fKBCRniISD0wAZviUmYHTUQtwBfCRqqqIZAL/An6hqp8FKmgTvkSE8wbk8v5tY7hrXH8+X1PG+Q/N5v73vqKyyoZ4GtPWWkz6bhv9LcC/gRXAq6q6TER+JyKXuMUmA1kiUgLcDjQM67wF6AP8WkQWuV+dAv5bmLCTEOvhB2N789EdY7loyEk8PmsNZz8wizcWbrYhnsa0IfuMXBMSFmzczW9nLGPx5r0M7Z7JPZcMZHDXzGCHZUzYsM/INWFlaPcOvPHD0/nTFYPZWH6Q8X/7jJ9PX0xphQ3xNCaQLOmbkBETI3y7sBsf33EWN57ZizcWbuGcB2bx99lrqa61IZ7GBIIlfRNy0hLjuPvCr/Hvn46hML8D976zgnGPzubjlTuDHZoxYc+SvglZvXJSefZ7I3h24nBQ+N6z87l+ynzWldkQT2OOlyV9E/LO7t+J9346hl9e2J9568r5+sOf8Md3VlBxqCbYoRkTdizpm7AQHxvDjWN689EdZ3HpKV14cvZaznnwE14r2kR9fWiNQDMmlFnSN2GlU1oif/7WEN780el07ZDEndOXcNnj/2Hhxt3BDs2YsGBJ34SlId0y+cfNp/HQt4ewbc9BLvu//3D7q4vYue9QsEMzJqRZ0jdhKyZG+ObQrnx0x1h+MLY3by/extkPzOKJT9ZQVVsX7PCMCUmW9E3YS02I5a5x/Xn/tjGM7p3Nfe9+xQUPz+aD5TtsSgdjfFjSNxEjPzuFp68rZOr1I/DECDc8V8TEZ+dTsnN/sEMzJmRY0jcR56y+Obz30zH8z0UDWLBhN+Memc0f3l7OPhviaYwlfROZ4jwxTDqjJx/fOZYrhnVl8mfrOOeBWbwyf6MN8TRRzZK+iWjZqQncd/lgZvzoDHpkpXDXP5Yy/m+fUbyhPNihGRMUlvRNVDi5awbTbx7NoxNOobSiissf/5yfvryQ7XttiKeJLpb0TdQQEcaf0oUPf3YWt5zdh3e+3M45D87ibx+XcKjGhnia6GBJ30SdlIRY7rigHx/cdhZnFmTz53+v5OsPz+bfy7bbEE8T8Szpm6jVPSuZJ68p5IVJI0mMi+Gm54u59pl5rN5REezQjGkzlvRN1DujIJt3fnwm91w8gMWb9jDu0Tn89q1l7D1oQzxN5LGkbwwQ64lh4uk9mXXn2UwY3o0p/1nP2Q/MYtrcjdTZEE8TQSzpG+OlY0o89152Mm/fegZ9clL55RtLueSxT5m3zoZ4mshgSd+YZgzsnMErN43ir1eeyu7Kar795Ofc+tJCFmzcbTV/E9Zigx2AMaFKRLh4SGfO+1ouj3+yhic/WcNbi7eSkRTHGX2yObMgmzF9c+icmRTsUI3xm4TaELXCwkItKioKdhjGHGHPgWrmrC5jzupSZq8qY7s7d3+fTqmNF4BRPbNIivcEOVITjUSkWFULWyxnSd+Y1lNVVu/cz+xVpcxeXcbctbuoqq0n3hPD8J4dGFOQw5i+OfTPS0NEgh2uiQKW9I1pR4dq6pi/vty5CKwqY6U71j8nLYEzC7I5q28Op/fJJjs1IciRmkgV0KQvIuOARwEP8LSq3uezPgF4DhgG7AK+o6rrRSQLmA4MB6ao6i0t7cuSvokE2/cecpqBVpfx6epSdh9wxvwP6pLOmQU5jCnIYViPDsTH2lgKExgBS/oi4gFWAecDm4H5wJWqutyrzA+Bwap6s4hMAC5T1e+ISApwKjAIGGRJ30Sjunpl2da9jXcBCzbuprZeSYn3MLp3lnMR6JtDflayNQWZ4+Zv0vdn9M4IoERV17obfhkYDyz3KjMeuMd9PR14TEREVSuBT0WkT2uCNyaSeGKEwV0zGdw1k1vOKaDiUA2fr9nF7NWlzFldxgcrdgLQtUMSY/o6dwGn9ckiPTEuyJGbSORP0u8CbPJ6vxkYebQyqlorInuBLKDMnyBE5EbgRoDu3bv78yPGhK20xDi+PjCPrw/MA2DDrsrGDuEZi7Yybe5GPDHCqd0yGdM3hzMLshncNRNPjN0FmBMXEuP0VfUp4ClwmneCHI4x7apHVgrXjE7hmtH51NTVs2DDbuasLmP26lIe/mAVD81cRWZyHKf3yWaMOzT0pAx7NsAcH3+S/hagm9f7ru6y5spsFpFYIAOnQ9cY0wpxnhhG9spiZK8s7rigH+WV1XxaUub2B5TyryXbACjolOr2BWQz0p4NMK3gT9KfDxSISE+c5D4BuMqnzAzgOuBz4ArgIw21saDGhKGOKfFcMqQzlwzpjKqyckcFc1Y5dwEvzN3AM5+tIz42hhH5HRnT17kL6JdrzwaYo/N3yOaFwCM4QzafUdV7ReR3QJGqzhCRROB5nJE65cAEr47f9UA6EA/sAb7uPfLHl43eMcY/h2rqmLvOeTZgzupSVu3YD0CntITGu4Az+mSTZc8GRAV7OMuYKLNt70HmrCrjk9WlfFZSxp4DNYjAoM4ZjOmbzZkFOQztbs8GRCpL+sZEsbp6ZemWvY13AQs27qGu8dmAbKcpqCCH/OyUYIdqAsSSvjGm0b5DNfynZJf7lHApm8oPAtC9Y3LjZHGn9c4izZ4NCFuW9I0xzVJV1u864M4WWsp/1uziQHUdnhhhaPfMxsniBnXJsGcDwoglfWOMX6pr61mwcbf7gFgpX27ZB0CHhmcD3KeE8zISgxypORZL+saY47JrfxWflpTxySpnmojSiioA+uamMqYghzP75jCyZ0cS4+zZgFBiSd8Yc8JUla+2VzTeBcxft5vqunoSYmMY0bNjY1NQ39xUezYgyCzpG2MC7mB1HV+s2+WOCiqjZKfzbEBuekLjbKFn9MmmY0p8kCONPoGcZdMYYwBIivdwdr9OnN2vEwBb9hxkjnsBmLl8B9OLNyMCJ3fJYExBDkO6ZdIzO4XuHZPt+YAQYTV9Y0xA1NUrizfvaZwmYuHG3dS76SVGoFvHZHpmp9ArO5WeOSn0yk6hZ3YKeemJxNgooRNmzTvGmKCqOFTDmtJK1pXtZ11pJWvLKllbWsm6skoO1tQ1lkuK85Cf3XQR6JmdQs+cFHpnp5KRbM8N+Muad4wxQZWWGMcp3TI5pVvmYctVlR37qlhbtp91XheC5dv28d6y7dTVN1VEO6bEN10IslPonZNCz+xUemQl2+ih42RJ3xjTrkSEvIxE8jISOa139mHraurq2VR+oPFCsLbMuVOYs7qU6cWbvbYBnTOS6OXVTNQzJ5Ve2Sl0zkyyh8qOwZK+MSZkxHli6JWTSq+c1CPW7a+qZX3DhaCh2aisktcXbKGiqraxXHxsDPlZye7dgXMhaOhD6JgSH/VDSy3pG2PCQmpCLIO6ZDCoS8Zhy1WVsv3VrHPvChr6DtaUVvLRVzupqWtqLkpPjG28I2hoMuqV43xPjo+OdBgdv6UxJmKJCDlpCeSkJTCiZ8fD1tXW1bN1zyHWlu1vbDJaV1bJvHXlvLHw8A8AzEtPbOxE7tV4MUila4ck4jyRM9zUkr4xJmLFemLonpVM96xkxvY7fN3B6jo2lDd1JK91m4zeXbqN3QdqmrYRI3TPSva6O0htvEPolJYQds1FlvSNMVEpKd5D/7x0+uelH7Fud2W124nc1HewtrSSOavLqKqtbyyXEu+hZ47XhcC9GORnp5AeotNUW9I3xhgfHVLiGZYSz7AeHQ5bXl+vbNt3qLEjuaH/YPGmPfxryVa8RpuSnZrQeHfQ0G/QKyeFbh2TSYgN3nBTS/rGGOOnmBihS2YSXTKTOKPg8OGmVbV1jcNNm0YYVfLhVzt5paiqaRteTyf3bHwozXlK+aR2eDrZkr4xxgRAQqyHPp3S6NMp7Yh1+w7VNF4EvJuN5q8rp7K66enkcQPzeOKaYW0apyV9Y4xpY+mJcQzplsmQZp5O3llR1diZ3Cktoc1jsaRvjDFBIiLkpieSm57I6N5Z7bLPyBl8aowxpkWW9I0xJoqE3NTKIlIKbDiBTWQDZQEKJ5AsrtaxuFrH4mqdSIyrh6rmtFQo5JL+iRKRIn/mlG5vFlfrWFytY3G1TjTHZc07xhgTRSzpG2NMFInEpP9UsAM4CourdSyu1rG4Widq44q4Nn3TvkSkO7AcyFDVupbKt7CtKcBmVf3vQMR2tG2LyJnA06rar6Wyx7mv/cBgVV17vPEa01YisaZv2oCIrBeRgyKy3+urs6puVNXUE034Lex7lIhUisgRH6ckIgtF5JbWbE9V5xwt4R9HbLNE5Aaf7ae2VcIXkatEpMg9/ttE5F0ROaMt9mUikyV90xoXuwmt4Wtre+xUVb8ANgNXeC8XkUHAAOCl9ogj2ETkduAR4H+BXKA78H/A+OPYlj2NH6XCMumLyDgRWSkiJSLyi2bWJ4jIK+76uSKSHyJxTRSRUhFZ5H7d0Nx22iCuZ0Rkp4h8eZT1IiJ/ceNeIiJDW7HtfBHRhiTi1nx/LyKfiUiFiLwvItle5V8Tke0istf9vusYcY11yy0C0oBf+xS5FnhHVXc1s+3ZIjLwGNvd7PX+VBFZ4Mb7CtABuFpElovIChH50v277RaRt0Wkq3vM5gNnAU+JyAEReczdnopIH/d1hog85/78BhH5bxGJcddNFJFPReQBd9vrROQbR4k5A/g9sBP4AzAP+KGqvqWqd7plpojI8w3HzP177vXaxnoRuUtElgCV7uvpPvt5VET+4hX7ZPeOYouI/EFEjpgTWEQSRWSeiCwWkWUi8ttmyrT7OelnXME6Jz3i3KW+3cy6tj1WqhpWX4AHWAP0AuKBxcAAnzI/BJ5wX08AXgmRuCYCjwXhmI0BhgJfHmX9hcC7gACjgLnNlFkPnNfM8nxAgVj3/Sz3OPQFktz393mVvx4ngScArwErG+ICpgB/8Co7Fnjbfd0NqAW6ue9jcGr/lx5l248Ai7zWNW7b3e5m93U8zsOAtwFxOHcTNTht/gA9gK3u8UtzY/6n1zGbhVPznuu1LwX6uK+fA950fzYfWAVM8vp/qAG+7/7//MDdlzRznMe5v/9w932au60BPr/j817HrPH39PobLnKPZZL7ux0A0rz+h7cBo9z3bwBPAilAJ5wLzU3NxCZAqvs6DpjbsI0gn5P+xDWR4JyTtwPTGv5W7XmswrGmPwIoUdW1qloNvMyRt7fjganu6+nAuSJt/plm/sQVFKo6Gyg/RpHxwHPq+ALIFJGTmin3TxHZ43798xjbe1ZVV6nqQeBV4BSvWJ5R1QpVrcJJdn3x445TVTfhJNhr3EXn4iT3fx1l2/cAQ9wa8rGMwkkIj6hqjapOB+YD291tbnDfZ6lqBXAvTu1+PE5CB1hLM8fMrRVPAO5241oPPOj1OwBsUNW/q9MnMhU4CafpxlcWUKaq8924KoAVQJcWfj9ff1HVTap60P3dFgCXuevOAQ6o6hcikotzYfupqlaq6k7gYff3OYz7f7PffRvnfvmOEGn3c9LPuNqdiHQF/gt4+ihF2vRYhWPS7wJs8nq/mSP/8RvLqGotsBfnpAl2XACXu00o00WkWxvH5C9/Y79UVTPdr0uPsb3tXq8PAKnQeEt7n4isEZF9ODVPOPZsr6Pd2/N3gQ9oSpjXAC+rak0L284+YouH6wxsUbda5WqcBkRE+uMkw8nudmcDmfh3zLJxEo33tCIbfMo1HitVPeC+PKLDGtgFZEtTM1o+cCpO7dXXaBFZDNzPkcd2k8/7acCV7uur3Pfg3AXEAdsaLvQ4tf5Ozeyv4fgvwml+mqmqvnEF45z0Jy5o/3PyEeDnQP1R1rfpsQrHpB/O3gLyVXUwMJOmq3m0uAqnFnMekIHT3HEsC3DmExkC/BW4AegqImcD3+Tw43e0bbdUQ9oGdPGpSXUHEGe00Ic4iXqEqqbjNJV5b/dYNccynOabHj7b3tJCTM35HKgCLnXj+gdOLXyfV5lKnATRcMw+5shk4Rvva8BYt/Z5GU1Jf5O7v2yvC326qjbbT6Kqdap6CtAVGCFOJ3vQ+RFXu56TInIRsFNVi9tyP8cSjkl/C06bZIOuHHkSNZZxa0YZODWloMalqrvcpgdwbu3a9iNy/OfPMQ2ENJxEsgtIxmkLPypV3ddwe66q7+DUWt8CnsVpFik63m17+RynrfzHIhInIt/EaaqLwUmsK3ES4B4R6Qj8xv25hmO2A6cfp7m/dx1O89a9IpImIj1w2nJf8DM2723txenI/hswx93uWyLyDRH5k1tsEc5FL15E8nDa9EW8OtKb2W4pTrPZs8A6VV3hLt8GvA88KCLpIhIjIr1F5KwW4tyDc7EZ57MqGOdki3EF4Zw8HbhERNbjNAGfIyK+/w9teqzCMenPBwpEpKeIxOO0Mc7wKTMDuM59fQXwkc/te1Di8mnzvQSnTTYUzACuFccoYK970gfaczi15i04D3R9cazCIpLXUAMXkYZE/BROzfk5n+Kt2nYDt//lmzgdeuXAd4DXgYtw/j5X43R6lrnbfM/90bdwRg896pbpDdzdzC5uxamBrwU+xalJP+NPbM14CKfztjPOBWATcAtOxzI4nbgrcZq23se5oEHLCWMazsVims/ya3E6upcDu3Hal4/o6xGRHBHJdF8nAecDX/kUa/dz0p+42vucVNW7VbWrqubj5IiPVPVqn2Jte6wC2SvcXl84HUyrcEaJ/Mpd9jvgEvd1Is5tawnOiINeIRLXH4FlOCN7Pgb6t1NcL+E0Y9TgtD1PAm4GbnbXC04Ncg2wFCgMkbhu8TpeXwCntVNcZ+A0gyzBqT0vcv+2QT1mfsbV7scMGAwsdOP6Evi1uzyo56SfcQXlnHT3PZamkVbtdqxsGgZjjIki4di8Y4wx5jhZ0jfGmCjS6qQvzTzSLyIdRWSmiKx2v3dwl4sc5+P9xhhjAq/VbfoiMgbYj/ME5yB32Z+AclW9T5w5Zzqo6l0iciHO6IULgZHAo6o68ljbz87O1vz8/Nb/JsYYE8WKi4vL1I/PyG31THuqOruZCYDG4/REg/NwwyzgLrwe7we+EJFMETlJjzEcMD8/n6KioqOtNsYY0wwR2dByqcC16ed6JfLtNM0d4tfj/SJyozhzhBeVlpYGKCRjjDG+Aj6ntqqqiLSqzUhVn8L9mLDCwkIbQ9q0cN5dAAARJElEQVROvtyyl/LKauJjY4jzxJAQG9P4Oj42hnif756Ytp6zzoQ6VaW6rp6aOqW6tr7pq67pe43XaxsS3jqd0hIZ1KWlOQJPTKCS/o6GZhv3Cbed7vL2erzftNLL8zbyi9eXtupnPDFCnEfci4CHhNgY5733xcK9QCT4XDzi3O8tXVhaXufsL8HjaXwf64m8QWgNydU7qdbUKtV1dVTV+iTdujqqa5vK19Q1n4x911XV1VPTzLoq3+Rd27De2YdpOxcNPonHrmrb8S6BSvoNjw3f535/02v5LSLyMk5Hbls93m9a4T8lZfz3P79kTN8cfnJuH+ckP+zErnMThfqc9EcmEd91VbX1VByqpdy75lfbtK6pBhi43ydGOPxuxeNz8Whhne/F5fB17kXN4yHOI9Sr+iTdusaab5Xv8Wg4Tkc5VkccR69jVVMX2Bpy08X62L97cnxs47oEz5HHsOGCHu9puAA3XXwTGrfpHKu42Bg8bT6jeWTJTI5r8320OumLyEs4nbbZ4nz60G9wkv2rIjIJZ/6Tb7vF38EZuVOCM8Xu9wIQszkBa0r3c/MLxfTKSeGxq04lPbHt/8maU1vXVHutarjIeCdTn9rrYTVRnxpqw7oqr2XN1Xb3V9U2s04bE3d1bT31J5hrmxKrHJZYvZvPEuJiSE2MbfZOxvuu6FjrEppN3kK81x2Q97q2/zgJEy6OZ/TOlUdZdW4zZRX4UWv3YdrG7spqrp8ynzhPDJOvGx60hA8Q64lxmmXiwZm2PTTU1evhFwufC0uMyJHNV141X0uuJtTZhyNHieraem56oZhtew/x0vdH0a1jcrBDCkmeGCEp3kNS/BEfBWtMRIi8HjBzBFXll28sZd66cv58xWCG9egQ7JCMMUFiST8KPP7JGqYXb+an5xUw/pTWfqSqMSaSWNKPcO8u3caf3lvJ+FM685NzC4IdjjEmyCzpR7Alm/dw26uLGNo9k/svH2ydjMYYS/qRauueg0yaWkR2agJPXVtIYpx1TBpjbPRORKqsquWGqUUcqq7jxRtGkp2aEOyQjDEhwpJ+hKmrV37y8kJW7qjgmYnD6ZubFuyQjDEhxJp3Iswf31nBByt2cs/FAzirb4tTaxtjoowl/Qgybe5Gnv50HRNPy+ea0fnBDscYE4Is6UeIT1eX8T9vfsnYfjn89399LdjhGGNClCX9CFCycz8/eLGYPjmp/PXKUyNyqmFjTGBYdghz5e4kagmxHiZPLCQtiJOoGWNCn43eCWNVtXXc9HwR2/cd4pUbR9G1g02iZow5NqvphylV5e5/LGX++t08+K0hnNrdJlEzxrTMkn6Y+tvHJby+cAu3n9+Xi4d0DnY4xpgwYUk/DP1ryTYeeH8Vl53ahVvP6RPscIwxYcSSfphZtGkPt7+6iMIeHbjv8pNtEjVjTKtY0g8jW/Yc5IapRXRKT+DJa4aREGuTqBljWsdG74SJ/VW1TJoyn6qaOl76/kiybBI1Y8xxsKQfBurqlR+/tJDVO/cz5XvDKbBJ1Iwxx8mad8LAvf9awUdf7eS3lwzkzAKbRM0Yc/ws6Ye4F77YwDOfreP603ty9agewQ7HGBPmLOmHsNmrSvnNjGWc078Tv7JJ1IwxAWBJP0St3lHBj15cQEGnVP5y5al4YmxopjHmxFnSD0G79ldx/dT5JMR5mDxxOKkJ1t9ujAkMS/oh5lBNHTc+X8zOfVU8fV0hXTKTgh2SMSaCWBUyhKgqd7++lOINu/m/7w7llG6ZwQ7JGBNhrKYfQv76UQlvLNzCnRf048KTTwp2OMaYCGRJP0S8tXgrD81cxTeHduGHY3sHOxxjTISypB8CFmzczc9eW8yI/I788Zs2iZoxpu0ELOmLyG0iskxEvhSRl0QkUUR6ishcESkRkVdEJD5Q+4sUm3cf4MbnijgpI5EnbBI1Y0wbC0jSF5EuwI+BQlUdBHiACcD9wMOq2gfYDUwKxP4iRcWhGiZNKaK6tp7J1w2nY4pdE40xbSuQzTuxQJKIxALJwDbgHGC6u34qcGkA9xfWauvqufWlhZSU7ufxq4fRp1NqsEMyxkSBgCR9Vd0CPABsxEn2e4FiYI+q1rrFNgNdmvt5EblRRIpEpKi0tDQQIYW8P/xrBbNWlvL78YM4vU92sMMxxkSJQDXvdADGAz2BzkAKMM7fn1fVp1S1UFULc3IifxbJ5z5fz5T/rOeGM3py1cjuwQ7HGBNFAtW8cx6wTlVLVbUGeB04Hch0m3sAugJbArS/sDVr5U7umbGM876Wy90X2iRqxpj2FaikvxEYJSLJ4ow3PBdYDnwMXOGWuQ54M0D7C0urdlRw67SF9M9L59EJp9gkasaYdheoNv25OB22C4Cl7nafAu4CbheREiALmByI/YWjsv1VXD9lPknxHiZPLCTFJlEzxgRBwDKPqv4G+I3P4rXAiEDtI1wdqqnjxueKKNtfxas3jeakDJtEzRgTHFbdbGOqys+nL2HBxj08cfVQBne1SdSMMcFj0zC0sUc+WM2MxVv5+bh+jBtkk6gZY4LLkn4benPRFh79cDXfGtaVH5xlk6gZY4LPkn4bKd5Qzp3TlzCiZ0fuvcwmUTPGhAZL+m1gU/kBbnyumM4ZiTx59TDiY+0wG2NCg2WjANt3qIbrp8ynpq6eyROH08EmUTPGhBAbvRNAtXX1/OjFBawrq+S5SSPonWOTqBljQosl/QD63dvLmbO6jPsvP5nTetskasaY0GPNOwEy5bN1PPf5Bm4a04vvDLdJ1IwxocmSfgB8/NVOfvf2cs4fkMvPx/UPdjjGGHNUlvRP0Ffb93HrSwv52kk2iZoxJvRZ0j8BOysOMWlKESkJHiZfN5zkeOsiMcaENstSx8mZRK2Y8spqXrt5NHkZicEOyRhjWmRJ/zjU1yt3vLaYxZv38MTVwxjUJSPYIRljjF+seec4PPLBKt5eso27xvXngoF5wQ7HGGP8Zkm/ld5YuJm/fFTCtwu7ctOYXsEOxxhjWsWSfivMX1/OXdOXMrpXFn+41CZRM8aEH0v6ftq46wA3PV9M1w5JPH71UJtEzRgTlixz+WHvwRqunzqfunpl8sThZCbbJGrGmPBkSb8FNXX13DJtARt2VfLE1cPomZ0S7JCMMea42ZDNY1BV7pmxjDmry/jTFYMZ3Tsr2CEZY8wJsZr+MTzz2XpenLuRm8/qzbcLuwU7HGOMOWGW9I/iwxU7+MO/ljNuYB4/v6BfsMMxxpiAsKTfjBXb9vHjlxYyqHMGD31nCDE2iZoxJkJY0vexc98hJk2ZT1piHE9fV2iTqBljIoplNC8Hq+v4/nNF7D5Qw2s3jyY33SZRM8ZEFkv6rvp65WevLWLJlr08dU2hTaJmjIlI1rzjemjmKt5Zup1ffuNrnD8gN9jhGGNMm7CkD/yjeDOPfVzClSO6ccOZPYMdjjHGtJmoT/rz1pXzi9eXcFrvLH43fpBNomaMiWhRnfTXl1Vy0/NFdOuYzOPfHUacJ6oPhzEmCgQsy4lIpohMF5GvRGSFiIwWkY4iMlNEVrvfOwRqfydq7wFnEjUFnrluOBnJccEOyRhj2lwgq7aPAu+pan9gCLAC+AXwoaoWAB+674Oupq6eH04rZlP5AZ68ehj5NomaMSZKBCTpi0gGMAaYDKCq1aq6BxgPTHWLTQUuDcT+ToSq8us3l/FZyS7++M3BjOxlk6gZY6JHoGr6PYFS4FkRWSgiT4tICpCrqtvcMtuBZsdCisiNIlIkIkWlpaUBCql5kz9dx0vzNvLDsb25YljXNt2XMcaEmkAl/VhgKPC4qp4KVOLTlKOqCmhzP6yqT6lqoaoW5uTkBCikI81cvoN731nBhSfnccfXbRI1Y0z0CVTS3wxsVtW57vvpOBeBHSJyEoD7fWeA9tdqy7bu5ScvL2Rwlwwe/NYpNomaMSYqBSTpq+p2YJOINFSfzwWWAzOA69xl1wFvBmJ/rbVj3yEmTSkiMymOv19bSFK8JxhhGGNM0AVy7p1bgRdFJB5YC3wP56LyqohMAjYA3w7g/vxysLqOG6YWse9QDdNvPo1ONomaMSaKBSzpq+oioLCZVecGah+tVV+v3PbKIr7cupe/X1PIgM7pwQrFGGNCQkQ/gvrn91fy3rLt/OrCr3GeTaJmjDGRm/RfLdrE47PWcNXI7kw6wyZRM8YYiNCk/8XaXfzqjaWcWZDNby8ZaJOoGWOMK+KS/rqySm5+oZjuHZN57KqhNomaMcZ4iaiMuOdANZOmzEeAZyYOJyPJJlEzxhhvEfNxidW19fzghQVs3n2QF78/kh5ZNomaMcb4ipiafvGG3cxfX879V5zM8PyOwQ7HGGNCUsTU9Ef3zuLDn51lNXxjjDmGiKnpA5bwjTGmBRGV9I0xxhybJX1jjIki4kxzHzpEpBRncrbjlQ2UBSicQLK4Wsfiah2Lq3UiMa4eqtriB5KEXNI/USJSpKrNTfwWVBZX61hcrWNxtU40x2XNO8YYE0Us6RtjTBSJxKT/VLADOAqLq3UsrtaxuFonauOKuDZ9Y4wxRxeJNX1jjDFHYUnfGGOiSFgmfREZJyIrRaRERH7RzPoEEXnFXT9XRPJDJK6JIlIqIovcrxvaKa5nRGSniHx5lPUiIn9x414iIkNDJK6xIrLX63j9up3i6iYiH4vIchFZJiI/aaZMux8zP+Nq92MmIokiMk9EFrtx/baZMu1+TvoZV7DOSY+ILBSRt5tZ17bHSlXD6gvwAGuAXkA8sBgY4FPmh8AT7usJwCshEtdE4LEgHLMxwFDgy6OsvxB4FxBgFDA3ROIaC7wdhON1EjDUfZ0GrGrmb9nux8zPuNr9mLnHINV9HQfMBUb5lAnGOelPXME6J28HpjX3t2rrYxWONf0RQImqrlXVauBlYLxPmfHAVPf1dOBcafvPTPQnrqBQ1dlA+TGKjAeeU8cXQKaInBQCcQWFqm5T1QXu6wpgBdDFp1i7HzM/42p37jHY776Nc798R4i0+znpZ1ztTkS6Av8FPH2UIm16rMIx6XcBNnm938yR//iNZVS1FtgLZIVAXACXu80B00WkWxvH5C9/Yw+G0e7t+bsiMrC9d+7eWp+KU0v0FtRjdoy4IAjHzG2uWATsBGaq6lGPVzuek/7EBe1/Tj4C/ByoP8r6Nj1W4Zj0w9lbQL6qDgZm0nQ1N81bgDOfyBDgr8A/23PnIpIK/AP4qarua899H0sLcQXlmKlqnaqeAnQFRojIoPbYb0v8iKtdz0kRuQjYqarFbbmfYwnHpL8F8L4ad3WXNVtGRGKBDGBXsONS1V2qWuW+fRoY1sYx+cufY9ruVHVfw+25qr4DxIlIdnvsW0TicBLri6r6ejNFgnLMWoormMfM3ece4GNgnM+qYJyTLcYVhHPydOASEVmP0wR8joi84FOmTY9VOCb9+UCBiPQUkXicjo4ZPmVmANe5r68APlK3VySYcfm0+V6C0yYbCmYA17ojUkYBe1V1W7CDEpG8hrZMERmB8//a5onC3edkYIWqPnSUYu1+zPyJKxjHTERyRCTTfZ0EnA985VOs3c9Jf+Jq73NSVe9W1a6qmo+TIz5S1at9irXpsQq7j0tU1VoRuQX4N86ImWdUdZmI/A4oUtUZOCfG8yJSgtNROCFE4vqxiFwC1LpxTWzruABE5CWcUR3ZIrIZ+A1Opxaq+gTwDs5olBLgAPC9EInrCuAHIlILHAQmtMPFG5za2DXAUrc9GOCXQHev2IJxzPyJKxjH7CRgqoh4cC4yr6rq28E+J/2MKyjnpK/2PFY2DYMxxkSRcGzeMcYYc5ws6RtjTBSxpG+MMVHEkr4xxkQRS/rGGBNFLOkbY0wUsaRvjDFR5P8BrOyuf50qnW8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #  training model \n",
    "model.apply(weights_init)\n",
    "num_epochs = 5\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "n_classes = 2\n",
    "for epoch in range(num_epochs):\n",
    "    print('Current Epoch: {}'.format(epoch))\n",
    "    for i, (samples, targets) in enumerate(train_loader):\n",
    "        \n",
    "        print('Current Batch Number: {}'.format(i+1))\n",
    "        train = Variable(samples.view(batch_size,1,-1))\n",
    "        targets = Variable(targets.type(torch.LongTensor))\n",
    "        \n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #setting up model for training\n",
    "        model.train()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        outputs = outputs.reshape(batch_size,2)\n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    count += 1\n",
    "    #accuracy at the end of epoch    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Predict test dataset\n",
    "    for samples, labels in test_loader:\n",
    "\n",
    "        test = Variable(samples.view(batch_size_test,1,-1))\n",
    "\n",
    "        #setting up in test mode\n",
    "        model.eval()\n",
    "        # Forward propagation\n",
    "        outputs = model(test)\n",
    "        outputs = outputs.view(batch_size_test, n_classes)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        predicted = torch.max(outputs.data, 1)[1].type(torch.FloatTensor)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += len(labels)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100 * correct / float(total)\n",
    "\n",
    "    loss_list.append(loss.data)\n",
    "    iteration_list.append(count)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('Final Loss curve')\n",
    "plt.plot(loss_list)\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('Final Validation Curve')\n",
    "plt.plot(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[123   0]\n",
      " [  1 144]]\n",
      "Accuracy Score: 99.6268656716418\n",
      "F1 Score: 99.65397923875432\n",
      "Precision Score: 100.0\n",
      "Recall Score: 99.3103448275862\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "accuracy_list = []\n",
    "f1_score_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "y_pred =[]\n",
    "y_true = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(vw_test_loader, 0):\n",
    "            #test_loader has 4 * 50000 batches with 4 values of labels in each batch \n",
    "            #it has 67 such batches \n",
    "            samples, labels = data\n",
    "            samples = Variable(samples.view(batch_size_val,1,-1))\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            outputs = model(samples)\n",
    "            outputs = outputs.view(batch_size_val, n_classes)\n",
    "            \n",
    "            predictions = torch.argmax(outputs, 1)\n",
    "            targets = labels\n",
    "            \n",
    "            y_pred.extend(predictions)\n",
    "            y_true.extend(targets)\n",
    "#             accuracy_list.append(accuracy_score(targets, predictions))\n",
    "#             f1_score_list.append(f1_score(targets, predictions))\n",
    "#             precision_list.append(precision_score(targets, predictions))\n",
    "#             recall_list.append(recall_score(targets, predictions))\n",
    "\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy Score: {}\".format(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"F1 Score: {}\". format(f1_score(y_true, y_pred) * 100))\n",
    "print(\"Precision Score: {}\".format(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Recall Score: {}\".format(recall_score(y_true, y_pred)* 100))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 0, 0, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 0, 1, 1]]])\n",
      "tensor([[[0, 1, 1, 0],\n",
      "         [0, 0, 1, 0],\n",
      "         [0, 0, 1, 1],\n",
      "         [1, 0, 1, 0]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5, 4],\n",
       "       [4, 3]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "output = torch.randn(1, 2, 4, 4)\n",
    "pred = torch.argmax(output, 1)\n",
    "print(pred)\n",
    "target = torch.empty(1, 4, 4, dtype=torch.long).random_(2)\n",
    "print(target)\n",
    "confusion_matrix(pred.view(-1), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
