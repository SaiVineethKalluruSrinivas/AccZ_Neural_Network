{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50001)\n",
      "[0.04913539 0.0478669  0.05771144 ... 0.16863332 0.05331072 0.04423187]\n",
      "(50000,)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import CubicSpline      \n",
    "from transforms3d.axangles import axangle2mat  \n",
    "\n",
    "\n",
    "\n",
    "data = sio.loadmat('./SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "\n",
    "\n",
    "class AccZDataset(Dataset):\n",
    "    def __init__(self,start_no,range_len):\n",
    "        data = sio.loadmat('./SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "        self.start_no = start_no\n",
    "        self.range_len = range_len\n",
    "        self.data_set = data['L23MatChunk']\n",
    "        self.n_trails = len(self.data_set)\n",
    "        self.train_set = np.zeros((1,50000))\n",
    "        \n",
    "        for i in range (0,self.n_trails):\n",
    "            curr = np.asarray(self.data_set[i][0][0][self.start_no : self.start_no+self.range_len]).reshape(1,self.range_len)\n",
    "            self.train_set = np.append(self.train_set, curr, axis = 0)\n",
    "\n",
    "        self.train_set = np.delete(self.train_set, (0), axis=0) #array of 20 * 50000\n",
    "        \n",
    "        labels = []\n",
    "        for i in range(0, self.n_trails):\n",
    "            if(i < 10):\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "        \n",
    "        labels = np.asarray(labels).reshape(self.n_trails,1)\n",
    "        self.train_set = np.append(self.train_set, labels, axis = 1)\n",
    "        print(self.train_set.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.train_set[idx][:-1]\n",
    "        label = self.train_set[idx][-1]\n",
    "\n",
    "        return sample, label \n",
    "\n",
    "\n",
    "\n",
    "dataset = AccZDataset(20,50000)\n",
    "real_value, real_label = dataset[13]\n",
    "print(real_value)\n",
    "print(real_value.shape)\n",
    "print(real_label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET PREPARATION FOR TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subaru Features numpy (20, 50000)\n",
      "Subaru Targets numpy (20,)\n"
     ]
    }
   ],
   "source": [
    "#DATASET PREPERATION\n",
    "\n",
    "\n",
    "data = sio.loadmat('./SBSB_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "start_no = 0\n",
    "range_len = 50000\n",
    "data_set = data['L23MatChunk']\n",
    "n_trials = len(data_set)\n",
    "total_set = np.zeros((1,50000))\n",
    "\n",
    "for i in range (20):\n",
    "\n",
    "    curr = np.asarray(data_set[i][0][0][start_no : start_no+range_len]).reshape(1,range_len)\n",
    "    total_set = np.append(total_set, curr, axis = 0)\n",
    "\n",
    "total_set = np.delete(total_set, (0), axis=0) \n",
    "\n",
    "labels = []\n",
    "for i in range(0, n_trials):\n",
    "    if(i < 10):\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "\n",
    "labels = np.asarray(labels).reshape(n_trials,1)\n",
    "total_set = np.append(total_set, labels, axis = 1)\n",
    "\n",
    "# total_set = np.append(total_set, total_set[0,:].reshape(1,-1), axis = 0)\n",
    "su_targets_numpy = total_set[:,-1]\n",
    "su_features_numpy = total_set[:,:-1]\n",
    "print(\"Subaru Features numpy {}\".format(su_features_numpy.shape))\n",
    "print(\"Subaru Targets numpy {}\".format(su_targets_numpy.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET PREPARATION FOR TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volkswagen Features numpy (21, 50000)\n",
      "Volkswagen Targets numpy (21,)\n"
     ]
    }
   ],
   "source": [
    "vw_data = sio.loadmat('./VWVW_6Khz_L23Mat_accZY_chunk_noTurn_noStatic.mat')\n",
    "vw_start_no = 0\n",
    "vw_range_len = 50000\n",
    "vw_data_set = data['L23MatChunk']\n",
    "vw_n_trials = len(data_set)\n",
    "vw_total_set = np.zeros((1,50000))\n",
    "\n",
    "for i in range (20):\n",
    "\n",
    "    vw_curr = np.asarray(vw_data_set[i][0][0][vw_start_no : vw_start_no + vw_range_len]).reshape(1,vw_range_len)\n",
    "    vw_total_set = np.append(vw_total_set, vw_curr, axis = 0)\n",
    "\n",
    "vw_total_set = np.delete(vw_total_set, (0), axis=0) \n",
    "\n",
    "vw_labels = []\n",
    "for i in range(0, vw_n_trials):\n",
    "    if(i < 10):\n",
    "        vw_labels.append(0)\n",
    "    else:\n",
    "        vw_labels.append(1)\n",
    "\n",
    "vw_labels = np.asarray(vw_labels).reshape(vw_n_trials,1)\n",
    "vw_total_set = np.append(vw_total_set, vw_labels, axis = 1)\n",
    "\n",
    "vw_total_set = np.append(vw_total_set, vw_total_set[0,:].reshape(1,-1), axis = 0)\n",
    "vw_targets_numpy = vw_total_set[:,-1]\n",
    "vw_features_numpy = vw_total_set[:,:-1]\n",
    "print(\"Volkswagen Features numpy {}\".format(vw_features_numpy.shape))\n",
    "print(\"Volkswagen Targets numpy {}\".format(vw_targets_numpy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numpy = su_features_numpy\n",
    "targets_numpy = su_targets_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FeaturesNumpy Database\n",
      "(20, 50000)\n",
      "Original TargetsNumpy Database\n",
      "(20,)\n",
      "FeaturesNumpy Output shape after jittering\n",
      "(300, 50000)\n",
      "TargetsNumpy Output shape after jittering\n",
      "(300,)\n",
      "FeaturesNumpy Output shape after magwarping\n",
      "(580, 50000)\n",
      "TargetsNumpy Output shape after magwarping\n",
      "(580,)\n",
      "FeaturesNumpy Output shape after rotation\n",
      "(860, 50000)\n",
      "TargetsNumpy Output shape after rotation\n",
      "(860,)\n"
     ]
    }
   ],
   "source": [
    "#DATA AUGMENTATION\n",
    "#SINGLE KERNEL \n",
    "\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "features_numpy_new = features_numpy.T\n",
    "\n",
    "print('Original FeaturesNumpy Database')\n",
    "print(features_numpy.shape)\n",
    "print('Original TargetsNumpy Database')\n",
    "print(targets_numpy.shape)\n",
    "\n",
    "\n",
    "#perform jittering\n",
    "def DA_Jitter(X, sigma= 0.05):\n",
    "    myNoise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n",
    "    return X+myNoise\n",
    "\n",
    "#perform scaling\n",
    "def DA_Scaling(X, sigma=0.1):\n",
    "    scalingFactor = np.random.normal(loc=1.0, scale=sigma, size=(1,X.shape[1])) # shape=(1,3)\n",
    "    myNoise = np.matmul(np.ones((X.shape[0],1)), scalingFactor)\n",
    "    return X*myNoise\n",
    "\n",
    "#perform magnitude warping \n",
    "def GenerateRandomCurves(X, sigma=0.2, knot=4):\n",
    "    xx = (np.ones((X.shape[1],1))*(np.arange(0,X.shape[0], (X.shape[0]-1)/(knot+1)))).transpose()\n",
    "    yy = np.random.normal(loc=1.0, scale=sigma, size=(knot+2, X.shape[1]))\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    cs_x = CubicSpline(xx[:,0], yy[:,0])\n",
    "    return np.array([cs_x(x_range)]).transpose()\n",
    "\n",
    "def DA_MagWarp(X, sigma):\n",
    "    return X * GenerateRandomCurves(X, sigma)\n",
    "\n",
    "#performing Rotation\n",
    "percent_value = 1\n",
    "percent_shift = (range_len / 100) * percent_value\n",
    "def DA_Rotation(X):\n",
    "    shift = np.random.randint(low=0 , high = percent_shift) #giving percent_value shift (if percent_value is 1, then 1% shift)\n",
    "    return np.roll(X, shift)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#implement jittering\n",
    "n_sets_jitter = 14\n",
    "sigma = [0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.3,0.7,0.9,0.1]\n",
    "#number of values in sigma list should match the n_sets_jitter value\n",
    "for j in range (n_sets_jitter):\n",
    "    for i in range(20):\n",
    "        features_numpy = np.append(features_numpy, DA_Jitter(features_numpy_new[:,i], sigma[j]).reshape(1,-1), axis = 0)\n",
    "    targets_numpy = np.append(targets_numpy, targets_numpy[0:20], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "print('FeaturesNumpy Output shape after jittering')\n",
    "print(features_numpy.shape)\n",
    "print('TargetsNumpy Output shape after jittering')\n",
    "print(targets_numpy.shape)\n",
    "\n",
    "# #implement scaling\n",
    "# features_numpy_new = features_numpy.T\n",
    "# n_sets_scaling = 22\n",
    "# sigma = [0.2,0.5,0.3,0.4,0.2,0.6,0.8,0.9,0.1,0.7,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.31,0.57,0.73]\n",
    "\n",
    "\n",
    "# for j in range (n_sets_scaling):\n",
    "#     for i in range(20):\n",
    "#         features_numpy = np.append(features_numpy, DA_Scaling(features_numpy_new[:,0].reshape(-1,1), sigma[j]).reshape(1,-1), axis = 0)\n",
    "#     targets_numpy = np.append(targets_numpy, targets_numpy[0:20], axis = 0)\n",
    "    \n",
    "\n",
    "# print('FeaturesNumpy Output shape after scaling')\n",
    "# print(features_numpy.shape)\n",
    "# print('TargetsNumpy Output shape after scaling')\n",
    "# print(targets_numpy.shape)\n",
    "\n",
    "\n",
    "#implement magnitude warping\n",
    "features_numpy_new = features_numpy.T\n",
    "n_sets_magwarp = 14\n",
    "sigma = [0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.3,0.7,0.9,0.1]\n",
    "#number of values in sigma list should match the n_sets_jitter value\n",
    "for j in range (n_sets_magwarp):\n",
    "    for i in range(20):\n",
    "        features_numpy = np.append(features_numpy, DA_MagWarp(features_numpy_new[:,i].reshape(-1,1), sigma[j]).reshape(1,-1), axis = 0)\n",
    "    targets_numpy = np.append(targets_numpy, targets_numpy[0:20], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "print('FeaturesNumpy Output shape after magwarping')\n",
    "print(features_numpy.shape)\n",
    "print('TargetsNumpy Output shape after magwarping')\n",
    "print(targets_numpy.shape)\n",
    "\n",
    "#implement Rotation\n",
    "features_numpy_new = features_numpy.T\n",
    "n_sets_rotation = 14\n",
    "\n",
    "for j in range (n_sets_rotation):\n",
    "    for i in range(20):\n",
    "        features_numpy = np.append(features_numpy, DA_Rotation(features_numpy_new[:,i].reshape(-1,1)).reshape(1,-1), axis = 0)\n",
    "    targets_numpy = np.append(targets_numpy, targets_numpy[0:20], axis = 0)\n",
    "\n",
    "\n",
    "print('FeaturesNumpy Output shape after rotation')\n",
    "print(features_numpy.shape)\n",
    "print('TargetsNumpy Output shape after rotation')\n",
    "print(targets_numpy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vw FeaturesNumpy Output shape after time warping\n",
      "(147, 50000)\n",
      "vw TargetsNumpy Output shape after time warping\n",
      "(147,)\n"
     ]
    }
   ],
   "source": [
    "#implementation of time warping\n",
    "def GenerateRandomCurves(X, sigma=0.2, knot=4):\n",
    "    xx = (np.ones((X.shape[1],1))*(np.arange(0,X.shape[0], (X.shape[0]-1)/(knot+1)))).transpose()\n",
    "    yy = np.random.normal(loc=1.0, scale=sigma, size=(knot+2, X.shape[1]))\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    cs_x = CubicSpline(xx[:,0], yy[:,0])\n",
    "    cs_y = CubicSpline(xx[:,1], yy[:,1])\n",
    "    cs_z = CubicSpline(xx[:,2], yy[:,2])\n",
    "    return np.array([cs_x(x_range),cs_y(x_range),cs_z(x_range)]).transpose()\n",
    "\n",
    "def DistortTimesteps(X, sigma=0.2):\n",
    "    tt = GenerateRandomCurves(X, sigma) # Regard these samples aroun 1 as time intervals\n",
    "    tt_cum = np.cumsum(tt, axis=0)        # Add intervals to make a cumulative graph\n",
    "    # Make the last value to have X.shape[0]\n",
    "    t_scale = [(X.shape[0]-1)/tt_cum[-1,0],(X.shape[0]-1)/tt_cum[-1,1],(X.shape[0]-1)/tt_cum[-1,2]]\n",
    "    tt_cum[:,0] = tt_cum[:,0]*t_scale[0]\n",
    "    tt_cum[:,1] = tt_cum[:,1]*t_scale[1]\n",
    "    tt_cum[:,2] = tt_cum[:,2]*t_scale[2]\n",
    "    return tt_cum\n",
    "\n",
    "def DA_TimeWarp(X, sigma=0.2):\n",
    "    tt_new = DistortTimesteps(X, sigma)\n",
    "    X_new = np.zeros(X.shape)\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    X_new[:,0] = np.interp(x_range, tt_new[:,0], X[:,0])\n",
    "    X_new[:,1] = np.interp(x_range, tt_new[:,1], X[:,1])\n",
    "    X_new[:,2] = np.interp(x_range, tt_new[:,2], X[:,2])\n",
    "    return X_new\n",
    "\n",
    "\n",
    "vw_features_numpy_new = vw_features_numpy.T\n",
    "\n",
    "n_sets_time_warping = 6\n",
    "sigmas = [0.3,0.15,0.1,0.25,0.2,0.05]\n",
    "\n",
    "for j in range (n_sets_time_warping):\n",
    "    for i in range(0,21,3):\n",
    "        ip = vw_features_numpy_new[:,i:i+3]\n",
    "        vw_features_numpy = np.append(vw_features_numpy, DA_TimeWarp(ip, sigmas[j]).T , axis = 0)\n",
    "\n",
    "vw_targets_numpy = np.repeat(vw_targets_numpy, n_sets_time_warping+1)\n",
    "print('vw FeaturesNumpy Output shape after time warping')\n",
    "print(vw_features_numpy.shape)\n",
    "print('vw TargetsNumpy Output shape after time warping')\n",
    "print(vw_targets_numpy.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numpy = np.append(features_numpy, vw_features_numpy,axis=0)\n",
    "targets_numpy = np.append(targets_numpy, vw_targets_numpy,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset with subaru and volkswagen data with time warping- Features shape: (1007, 50000)\n",
      "Total dataset with subaru and volkswagen data with time warping- Targets shape: (1007,)\n"
     ]
    }
   ],
   "source": [
    "print('Total dataset with subaru and volkswagen data with time warping- Features shape:', features_numpy.shape)\n",
    "print('Total dataset with subaru and volkswagen data with time warping- Targets shape:', targets_numpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET PREPARATION FOR TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset dimensions\n",
      "Shape of Features Train Dataset\n",
      "torch.Size([805, 50000])\n",
      "Shape of Targets Train Dataset\n",
      "torch.Size([805])\n",
      "Shape of Features Validation Dataset\n",
      "torch.Size([202, 50000])\n",
      "Shape of Targets Validation Dataset\n",
      "torch.Size([202])\n"
     ]
    }
   ],
   "source": [
    "#TRAIN AND TEST SPLIT\n",
    "\n",
    "\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42)\n",
    "\n",
    "\n",
    "featuresTrain = torch.from_numpy(features_train).type(torch.FloatTensor)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.FloatTensor)\n",
    "\n",
    "featuresTest = torch.from_numpy(features_test).type(torch.FloatTensor)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 35\n",
    "batch_size_val = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "val_loader = torch.utils.data.DataLoader(test, batch_size = batch_size_val, shuffle = False)\n",
    "\n",
    "\n",
    "print(\"Training dataset dimensions\")\n",
    "print('Shape of Features Train Dataset')\n",
    "print(featuresTrain.size())\n",
    "print('Shape of Targets Train Dataset')\n",
    "print(targetsTrain.size())\n",
    "print('Shape of Features Validation Dataset')\n",
    "print(featuresTest.size())\n",
    "print('Shape of Targets Validation Dataset')\n",
    "print(targetsTest.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv1d(1, 1, kernel_size=(25,), stride=(10,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1d(1, 1, kernel_size=(10,), stride=(5,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1d(1, 1, kernel_size=(10,), stride=(3,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (avgLayer): AvgPool1d(kernel_size=(10,), stride=(2,), padding=(0,))\n",
       "  (fc1): Linear(in_features=161, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Designing the model\n",
    "\n",
    "filters = 1\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 1, out_channels = filters,kernel_size=25, stride=10),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(filters))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = filters, out_channels = filters, kernel_size=10, stride=5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(filters))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = filters, out_channels = filters, kernel_size=10, stride=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(filters)) # 250\n",
    "        self.avgLayer = nn.AvgPool1d(10, stride = 2)\n",
    "        self.fc1 = nn.Linear(161,2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out) \n",
    "        out = self.avgLayer(out)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        return Variable(hidden)\n",
    "    \n",
    "    \n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        torch.nn.init.xavier_uniform(m.weight.data, nn.init.calculate_gain('relu'))\n",
    "        m.bias.data.zero_()\n",
    "    \n",
    "\n",
    "model = ConvNet()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saivineethks/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saivineethks/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1  Loss: 0.5879404544830322  Accuracy: 50 %\n",
      "Current Epoch: 1\n",
      "Iteration: 2  Loss: 0.5185731649398804  Accuracy: 59 %\n",
      "Current Epoch: 2\n",
      "Iteration: 3  Loss: 0.45544055104255676  Accuracy: 82 %\n",
      "Current Epoch: 3\n",
      "Iteration: 4  Loss: 0.401611864566803  Accuracy: 83 %\n",
      "Current Epoch: 4\n",
      "Iteration: 5  Loss: 0.35861101746559143  Accuracy: 83 %\n",
      "Current Epoch: 5\n",
      "Iteration: 6  Loss: 0.3254183530807495  Accuracy: 84 %\n",
      "Current Epoch: 6\n",
      "Iteration: 7  Loss: 0.2993936538696289  Accuracy: 84 %\n",
      "Current Epoch: 7\n",
      "Iteration: 8  Loss: 0.27973660826683044  Accuracy: 85 %\n",
      "Current Epoch: 8\n",
      "Iteration: 9  Loss: 0.2644103169441223  Accuracy: 85 %\n",
      "Current Epoch: 9\n",
      "Iteration: 10  Loss: 0.2520867586135864  Accuracy: 85 %\n",
      "Current Epoch: 10\n",
      "Iteration: 11  Loss: 0.24259521067142487  Accuracy: 85 %\n",
      "Current Epoch: 11\n",
      "Iteration: 12  Loss: 0.23476426303386688  Accuracy: 86 %\n",
      "Current Epoch: 12\n",
      "Iteration: 13  Loss: 0.22823931276798248  Accuracy: 87 %\n",
      "Current Epoch: 13\n",
      "Iteration: 14  Loss: 0.2227608859539032  Accuracy: 88 %\n",
      "Current Epoch: 14\n",
      "Iteration: 15  Loss: 0.21798989176750183  Accuracy: 88 %\n",
      "Current Epoch: 15\n",
      "Iteration: 16  Loss: 0.21394047141075134  Accuracy: 88 %\n",
      "Current Epoch: 16\n",
      "Iteration: 17  Loss: 0.21023571491241455  Accuracy: 88 %\n",
      "Current Epoch: 17\n",
      "Iteration: 18  Loss: 0.20697689056396484  Accuracy: 88 %\n",
      "Current Epoch: 18\n",
      "Iteration: 19  Loss: 0.2041262984275818  Accuracy: 88 %\n",
      "Current Epoch: 19\n",
      "Iteration: 20  Loss: 0.2016524374485016  Accuracy: 88 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x130886908>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #  training model \n",
    "model.apply(weights_init)\n",
    "num_epochs = 20\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "n_classes = 2\n",
    "for epoch in range(num_epochs):\n",
    "    print('Current Epoch: {}'.format(epoch))\n",
    "    for i, (samples, targets) in enumerate(train_loader):\n",
    "        \n",
    "        train = Variable(samples.view(batch_size,1,-1))\n",
    "        targets = Variable(targets.type(torch.LongTensor))\n",
    "        \n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #setting up model for training\n",
    "        model.train()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        outputs = outputs.reshape(batch_size,2)\n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    count += 1\n",
    "    #accuracy at the end of epoch    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Predict test dataset\n",
    "    for samples, labels in val_loader:\n",
    "\n",
    "        test = Variable(samples.view(batch_size_val,1,-1))\n",
    "\n",
    "        #setting up in test mode\n",
    "        model.eval()\n",
    "        # Forward propagation\n",
    "        outputs = model(test)\n",
    "        outputs = outputs.view(batch_size_val, n_classes)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        predicted = torch.max(outputs.data, 1)[1].type(torch.FloatTensor)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += len(labels)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100 * correct / float(total)\n",
    "\n",
    "    loss_list.append(loss.data)\n",
    "    iteration_list.append(count)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "\n",
    "    print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('Final Loss curve')\n",
    "plt.plot(loss_list)\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('Final Validation Curve')\n",
    "plt.plot(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "accuracy_list = []\n",
    "f1_score_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "y_pred =[]\n",
    "y_true = []\n",
    "\n",
    "batch_size_val = 16\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(vw_test_loader, 0):\n",
    "            samples, labels = data\n",
    "            samples = Variable(samples.view(batch_size_test,1,-1))\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            outputs = model(samples)\n",
    "            outputs = outputs.view(batch_size_test, n_classes)\n",
    "            \n",
    "            predictions = torch.argmax(outputs, 1)\n",
    "            targets = labels\n",
    "            \n",
    "            y_pred.extend(predictions)\n",
    "            y_true.extend(targets)\n",
    "\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy Score: {}\".format(accuracy_score(y_true, y_pred) * 100))\n",
    "print(\"F1 Score: {}\". format(f1_score(y_true, y_pred) * 100))\n",
    "print(\"Precision Score: {}\".format(precision_score(y_true, y_pred) * 100))\n",
    "print(\"Recall Score: {}\".format(recall_score(y_true, y_pred)* 100))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "output = torch.randn(1, 2, 4, 4)\n",
    "pred = torch.argmax(output, 1)\n",
    "print(pred)\n",
    "target = torch.empty(1, 4, 4, dtype=torch.long).random_(2)\n",
    "print(target)\n",
    "confusion_matrix(pred.view(-1), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
